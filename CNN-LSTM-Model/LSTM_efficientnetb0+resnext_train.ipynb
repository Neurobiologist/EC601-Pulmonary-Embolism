{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "from tqdm import tqdm as tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Level\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyLevelDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Kaggle PE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, stage):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.pedataframe = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.hdf5_filename1 = '/scratch/efficientb0_features.hdf5'\n",
    "        self.hdf5_filename2 = '/scratch/resnet_features.hdf5'\n",
    "        #self.hdf5_filename2 = '/scratch/combined_features.hdf5'\n",
    "        \n",
    "        self._generate_row_indices_list()\n",
    "        \n",
    "        self.stage = stage\n",
    "        \n",
    "        if self.stage == 'train':\n",
    "            self.start = 0\n",
    "            self.end = 2650\n",
    "        else:\n",
    "            self.start = 2660\n",
    "            self.end = 3500\n",
    "        \n",
    "        # 0 - 2650 train\n",
    "        # 2660 - 3500 valid\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return number of 2D images. (Each CT slice is an independent image.)\"\"\"\n",
    "        #return len(self.pedataframe)\n",
    "        return self.end - self.start + 1\n",
    "        #return num_pos_samples_per_dataset + num_neg_samples_per_dataset\n",
    "        \n",
    "    def _generate_row_indices_list(self):\n",
    "        # group slice indices into studies\n",
    "        self.row_indices = [] # index into train df for every study\n",
    "        current_study_id = ''\n",
    "\n",
    "        for slice_index in range(len(self.pedataframe)):\n",
    "            new_study_id = self.pedataframe.StudyInstanceUID[slice_index]\n",
    "            if new_study_id != current_study_id:\n",
    "                self.row_indices.append(slice_index)\n",
    "                current_study_id = new_study_id\n",
    "            if slice_index % 100000 == 0:\n",
    "                print(slice_index)\n",
    "        \n",
    "    def __getitem__(self, study_index):\n",
    "        '''  '''\n",
    "        study_index = study_index + self.start\n",
    "        \n",
    "        h5py_file1 = h5py.File(self.hdf5_filename1, \"r\")\n",
    "        h5py_file2 = h5py.File(self.hdf5_filename2, \"r\")\n",
    "        \n",
    "        start_index = self.row_indices[study_index]\n",
    "        if study_index+1 < len(self.row_indices):\n",
    "            stop_index = self.row_indices[study_index+1]\n",
    "        else:\n",
    "            stop_index = len(self.pedataframe)\n",
    "            \n",
    "        # dim: seq_len x embedding_dim\n",
    "        x = np.ones((stop_index-start_index, 3328))  #embedding dim = 1280 for efficientnetb0 resnet 2048 1280+2048=3328\n",
    "        y = np.ones(stop_index-start_index)\n",
    "            \n",
    "        for slice_index in range(start_index, stop_index):\n",
    "            data_identifier = 'tensor(' + str(slice_index) + ')'\n",
    "            #slice_embeddings = h5py_file1[data_identifier][:].copy()\n",
    "            #slice_embeddings.append(h5py_file2[data_identifier][:])\n",
    "            #slice_embeddings[:len(h5py_file2[data_identifier][:])] += h5py_file2[data_identifier][:]\n",
    "            slice_embeddings = np.concatenate((h5py_file1[data_identifier][:], h5py_file2[data_identifier][:]),axis=0)\n",
    "            x[slice_index-start_index,:] = slice_embeddings\n",
    "            \n",
    "            pe_present_on_image = float(int(self.pedataframe.pe_present_on_image[slice_index]))\n",
    "            y[slice_index-start_index] = pe_present_on_image\n",
    "        \n",
    "        h5py_file1.close()\n",
    "        h5py_file2.close()\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename1 = '/scratch/efficientb0_features.hdf5'\n",
    "h5py_file1 = h5py.File(hdf5_filename1, \"r\")\n",
    "h5py_file1['tensor(12)'][:]\n",
    "\n",
    "h5py_file1.close()\n",
    "\n",
    "hdf5_filename2 = '/scratch/resnet_features.hdf5'\n",
    "h5py_file2 = h5py.File(hdf5_filename2, \"r\")\n",
    "h5py_file2['tensor(12)'][:]\n",
    "\n",
    "h5py_file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection/'\n",
    "train_csv = data_dir + 'train.csv'\n",
    "train_dir = data_dir + 'train/'\n",
    "train_dataset = StudyLevelDataset(csv_file=train_csv, stage='train')\n",
    "valid_dataset = StudyLevelDataset(csv_file=train_csv, stage='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "'''\n",
    "\n",
    "batch_size = 1\n",
    "embedding_dim = 3328\n",
    "nb_lstm_units = 64\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, nb_layers=1, nb_lstm_units=nb_lstm_units, \n",
    "                 embedding_dim=embedding_dim, batch_size=batch_size):\n",
    "        \n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.linear = nn.Linear(self.nb_lstm_units, 1)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_h0 = torch.randn(self.nb_layers, self.batch_size, self.nb_lstm_units)\n",
    "        hidden_c0 = torch.randn(self.nb_layers, self.batch_size, self.nb_lstm_units)\n",
    "\n",
    "        hidden_h0 = hidden_h0.to(device)\n",
    "        hidden_c0 = hidden_c0.to(device)\n",
    "\n",
    "        hidden_h0 = Variable(hidden_h0)\n",
    "        hidden_c0 = Variable(hidden_c0)\n",
    "\n",
    "        return (hidden_h0.to(device), hidden_c0.to(device))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # reset the LSTM hidden state. Must be done before you run a new batch. Otherwise the LSTM will treat\n",
    "        # a new batch as a continuation of a sequence\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        batch_size, seq_len, _ = X.size()\n",
    "\n",
    "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        #X = torch.nn.utils.rnn.pack_padded_sequence(x, X_lengths, batch_first=True)\n",
    "\n",
    "        # now run through LSTM\n",
    "        X, self.hidden = self.lstm(X, self.hidden)\n",
    "\n",
    "        # undo the packing operation\n",
    "        #X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "\n",
    "        # this one is a bit tricky as well. First we need to reshape the data so it goes into the linear layer\n",
    "        X = X.contiguous()\n",
    "        X = X.view(-1, X.shape[2])\n",
    "\n",
    "        # run through actual linear layer\n",
    "        X = self.linear(X)\n",
    "\n",
    "        # ---------------------\n",
    "        # 4. Create softmax activations bc we're doing classification\n",
    "        # Dim transformation: (batch_size * seq_len, nb_lstm_units) -> (batch_size, seq_len, nb_tags)\n",
    "        #X = torch.sigmoid(X)\n",
    "\n",
    "        # I like to reshape for mental sanity so we're back to (batch_size, seq_len, nb_tags)\n",
    "        X = X.view(batch_size, seq_len)\n",
    "\n",
    "        Y_hat = X\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLSTM(\n",
       "  (lstm): LSTM(3328, 64, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyLSTM()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model.to(device)\n",
    "x,y = train_dataset[1]\n",
    "x = torch.tensor(x)\n",
    "x = x.unsqueeze(0).float()\n",
    "x = x.to(device)\n",
    "\n",
    "pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 17:45:30 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.59039, mean: 0.11461: 100%|██████████| 2651/2651 [07:06<00:00,  6.21it/s]\n",
      "100%|██████████| 841/841 [02:15<00:00,  6.22it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 17:54:52 2020 Epoch 1, lr: 0.1000000, train loss: 0.11461, valid loss: 0.11209\n",
      "pos loss: 0.97172, neg loss: 0.06368, pos mean: 0.51804, neg mean 0.05103\n",
      "Tue Dec  8 17:54:52 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.54337, mean: 0.10918: 100%|██████████| 2651/2651 [06:49<00:00,  6.47it/s]\n",
      "100%|██████████| 841/841 [02:13<00:00,  6.31it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:03:55 2020 Epoch 2, lr: 0.1000000, train loss: 0.10918, valid loss: 0.10976\n",
      "pos loss: 0.92341, neg loss: 0.06382, pos mean: 0.53065, neg mean 0.05113\n",
      "Tue Dec  8 18:03:55 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.53598, mean: 0.10697: 100%|██████████| 2651/2651 [07:00<00:00,  6.31it/s]\n",
      "100%|██████████| 841/841 [02:19<00:00,  6.04it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:13:15 2020 Epoch 3, lr: 0.1000000, train loss: 0.10697, valid loss: 0.10674\n",
      "pos loss: 0.89275, neg loss: 0.06235, pos mean: 0.54331, neg mean 0.05005\n",
      "Tue Dec  8 18:13:15 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.50105, mean: 0.10440: 100%|██████████| 2651/2651 [07:03<00:00,  6.25it/s]\n",
      "100%|██████████| 841/841 [02:11<00:00,  6.41it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:22:30 2020 Epoch 4, lr: 0.1000000, train loss: 0.10440, valid loss: 0.10176\n",
      "pos loss: 0.93432, neg loss: 0.05487, pos mean: 0.52761, neg mean 0.04419\n",
      "Tue Dec  8 18:22:30 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.50699, mean: 0.10303: 100%|██████████| 2651/2651 [06:57<00:00,  6.34it/s]\n",
      "100%|██████████| 841/841 [02:12<00:00,  6.32it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:31:41 2020 Epoch 5, lr: 0.1000000, train loss: 0.10303, valid loss: 0.10105\n",
      "pos loss: 1.01042, neg loss: 0.05002, pos mean: 0.49458, neg mean 0.04109\n",
      "Tue Dec  8 18:31:41 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.50169, mean: 0.10319: 100%|██████████| 2651/2651 [06:57<00:00,  6.34it/s]\n",
      "100%|██████████| 841/841 [02:13<00:00,  6.29it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:40:52 2020 Epoch 6, lr: 0.1000000, train loss: 0.10319, valid loss: 0.10107\n",
      "pos loss: 0.93751, neg loss: 0.05401, pos mean: 0.52824, neg mean 0.04355\n",
      "Tue Dec  8 18:40:52 2020 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.51036, mean: 0.10273: 100%|██████████| 2651/2651 [06:55<00:00,  6.38it/s]\n",
      "100%|██████████| 841/841 [02:20<00:00,  5.99it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:50:08 2020 Epoch 7, lr: 0.1000000, train loss: 0.10273, valid loss: 0.10037\n",
      "pos loss: 0.93675, neg loss: 0.05333, pos mean: 0.52664, neg mean 0.04330\n",
      "Tue Dec  8 18:50:08 2020 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.52157, mean: 0.10226: 100%|██████████| 2651/2651 [06:58<00:00,  6.34it/s]\n",
      "100%|██████████| 841/841 [02:12<00:00,  6.37it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 18:59:19 2020 Epoch 8, lr: 0.1000000, train loss: 0.10226, valid loss: 0.09905\n",
      "pos loss: 0.93840, neg loss: 0.05192, pos mean: 0.53407, neg mean 0.04169\n",
      "Tue Dec  8 18:59:19 2020 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.51058, mean: 0.10136: 100%|██████████| 2651/2651 [06:57<00:00,  6.34it/s]\n",
      "100%|██████████| 841/841 [02:15<00:00,  6.20it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:08:32 2020 Epoch 9, lr: 0.1000000, train loss: 0.10136, valid loss: 0.09756\n",
      "pos loss: 0.95502, neg loss: 0.04942, pos mean: 0.53320, neg mean 0.03954\n",
      "Tue Dec  8 19:08:32 2020 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.52366, mean: 0.10139: 100%|██████████| 2651/2651 [06:58<00:00,  6.33it/s]\n",
      "100%|██████████| 841/841 [02:15<00:00,  6.22it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:17:46 2020 Epoch 10, lr: 0.1000000, train loss: 0.10139, valid loss: 0.09846\n",
      "pos loss: 0.95415, neg loss: 0.05047, pos mean: 0.52921, neg mean 0.04068\n",
      "Tue Dec  8 19:17:46 2020 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.01318, mean: 0.13482:   2%|▏         | 51/2651 [00:05<04:52,  8.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f67b2458c292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-f67b2458c292>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    739\u001b[0m         raise ValueError(\n\u001b[1;32m    740\u001b[0m             \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n\u001b[0;32m--> 741\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bce = torch.nn.BCEWithLogitsLoss()\n",
    "def criterion(logits, target):\n",
    "    loss = bce(logits.view(-1), target.view(-1))\n",
    "    return loss\n",
    "\n",
    "dummy = None\n",
    "\n",
    "def train_epoch(model, loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward pass\n",
    "        logits = model(data.float())\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # backpropagate the loss (backward pass)\n",
    "        loss.backward()\n",
    " \n",
    "        # update parameters based on accumulated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "        train_loss.append(loss_np)\n",
    "        average_loss = sum(train_loss) / len(train_loss)\n",
    "        bar.set_description('loss: %.5f, mean: %.5f' % (loss_np, average_loss))\n",
    "\n",
    "    return float(average_loss)\n",
    "\n",
    "def valid_epoch(model, loader):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    pos_logits = []\n",
    "    neg_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data.float())\n",
    "\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "            val_loss.append(float(loss_np))\n",
    "\n",
    "            logits = logits.squeeze()\n",
    "            target = target.squeeze()\n",
    "            \n",
    "            for i in range(logits.shape[-1]):\n",
    "                b = target[i].detach().cpu().numpy()\n",
    "                if b == 1:\n",
    "                    pos_logits.append(float(logits[i].detach().cpu().numpy()))\n",
    "                else:\n",
    "                    neg_logits.append(float(logits[i].detach().cpu().numpy()))\n",
    "                    \n",
    "    val_loss_mean = sum(val_loss) / len(val_loss)\n",
    "    \n",
    "    neg_logits_tensor = torch.FloatTensor(neg_logits).cuda()\n",
    "    pos_logits_tensor = torch.FloatTensor(pos_logits).cuda()\n",
    "    \n",
    "    neg_loss = criterion(neg_logits_tensor, torch.zeros(neg_logits_tensor.shape).float().cuda())\n",
    "    pos_loss = criterion(pos_logits_tensor, torch.ones(pos_logits_tensor.shape).float().cuda())\n",
    "    \n",
    "    neg_loss = neg_loss.detach().cpu().numpy()\n",
    "    pos_loss = pos_loss.detach().cpu().numpy()\n",
    "    \n",
    "    neg_mean = float(torch.sigmoid(neg_logits_tensor).mean().detach().cpu().numpy())\n",
    "    pos_mean = float(torch.sigmoid(pos_logits_tensor).mean().detach().cpu().numpy())\n",
    "    \n",
    "    return float(val_loss_mean), float(pos_loss), float(neg_loss), pos_mean, neg_mean\n",
    "\n",
    "def get_optimizer(lr, model):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "    return optimizer\n",
    "\n",
    "init_lr = 0.1\n",
    "n_epochs = 20\n",
    "device = 'cuda'\n",
    "\n",
    "# reduce LR by gamma three times every 10 epochs\n",
    "# each epoch is 100,000 samples\n",
    "#gamma = 10\n",
    "#schedule = [10, 20, 30]\n",
    "\n",
    "#model = resnext101.to(device)\n",
    "optimizer = get_optimizer(init_lr, model)\n",
    "model.to(device)\n",
    "\n",
    "master_train_loss = []\n",
    "master_valid_loss = []\n",
    "epoch = 1\n",
    "#best_valid_loss = 10\n",
    "\n",
    "\n",
    "while epoch <= n_epochs:\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "    \n",
    "    # update learning rate \n",
    "    #if epoch in schedule:\n",
    "    #    new_lr = optimizer.param_groups[0][\"lr\"] / gamma\n",
    "     #   optimizer = get_optimizer(new_lr, model)\n",
    "    \n",
    "    #train_loader, valid_loader = get_loaders(epoch)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,num_workers=1)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1,num_workers=1)\n",
    "\n",
    "    # train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # validate\n",
    "    valid_loss, pos_loss, neg_loss, pos_mean, neg_mean = valid_epoch(model, valid_loader)\n",
    "    #valid_loss = 0\n",
    "    #pos_loss  = 0\n",
    "    #neg_loss = 0\n",
    "    #pos_mean = 0\n",
    "    #neg_mean = 0\n",
    "    \n",
    "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(valid_loss):.5f}'\n",
    "    print(content)\n",
    "    content = f'pos loss: {(pos_loss):.5f}, neg loss: {(neg_loss):.5f}, pos mean: {(pos_mean):.5f}, neg mean {(neg_mean):.5f}'\n",
    "    print(content)\n",
    "    master_train_loss.append(train_loss)\n",
    "    master_valid_loss.append(valid_loss)\n",
    "    \n",
    "    # save loss data and model weights\n",
    "    #with open('train_loss.pkl', 'wb') as f:\n",
    "        #pickle.dump(master_train_loss, f)\n",
    "    #with open('valid_loss.pkl', 'wb') as f:\n",
    "        #pickle.dump(master_valid_loss, f)\n",
    "        \n",
    "        #torch.save(model.state_dict(), 'model-resnext-50-{}.pth'.format(epoch))\n",
    "        #best_valid_loss = valid_loss\n",
    "    \n",
    "    epoch += 1\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b6a15e13610>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3wVVdrA8d+TTkJoIQQIoYcSUVADKCogStMVLKioi2JDcdFVX3dFd9/1Xcuq69pFFwTsgoKoWBBRQFFACSC9hR4EEnoo6c/7x0zgkgRyA0km5fl+PveTO+fMmXlulPvkzDlzRlQVY4wxxleA1wEYY4ypeCw5GGOMKcSSgzHGmEIsORhjjCnEkoMxxphCgrwOoDTUr19fmzdv7nUYxhhTqSxcuHCXqkYXVVclkkPz5s1JSkryOgxjjKlURGTziersspIxxphC/EoOItJPRNaISLKIjCyivruILBKRHBEZVKDuGxHZJyJfFih/W0Q2ishv7quTWy4i8op7rqUics7pfEBjjDElV2xyEJFAYBTQH0gAbhCRhAK7bQGGAh8WcYjngCEnOPxfVLWT+/rNLesPxLuvYcAbxcVojDGmdPnTc+gCJKvqBlXNAiYCA313UNVNqroUyCvYWFW/B9JLENNA4F11zAfqiEijErQ3xhhzmvxJDrHAVp/tFLesNDzlXjp6UURCS3I+ERkmIkkikpSWllZK4RhjjAFvB6QfAdoBnYF6wMMlaayqY1Q1UVUTo6OLnIlljDHmFPmTHLYBcT7bTdyy06Kq291LR5nAWziXr8rsfMYYY/znT3JYAMSLSAsRCQEGA1NP98T54wgiIsCVwHK3aipwsztr6Txgv6puP93zFWXz7kP884sVZOcWGioxxphqrdjkoKo5wAhgOrAK+FhVV4jI4yIyAEBEOotICnAtMFpEVuS3F5E5wCTgEhFJEZG+btUHIrIMWAbUB550y78GNgDJwJvAPaXwOYuUnHqQt37exEcLtha/szHGVCNSFR72k5iYqKdyh7Sqct3oeWzafZgf/tKT8JAqccO4Mcb4RUQWqmpiUXXV+g5pEWFk/3akpWcy/qeNXodjjDEVRrVODgDnNqtH74QYRv+wgT2HsrwOxxhjKoRqnxwA/tq3LYeychg1K9nrUIwxpkKw5ADEx0Qy6NwmvDdvMyl7D3sdjjHGeM6Sg+v+S9uAwAsz1nodijHGeM6Sg6txnRrc2q05ny7exuodB7wOxxhjPGXJwcfwnq2IDA3i39+s8ToUY4zxlCUHH3XCQxjeszUzV6fyy4bdXodjjDGeseRQwNBuzYmpFcoz36ymKtwgaIwxp8KSQwE1QgJ54NI2LN6yj29X7vQ6HGOM8YQlhyIMOrcJraIj+Pc3q8mxRfmMMdWQJYciBAUG8Je+7VifdohPFqV4HY4xxpQ7Sw4n0PeMGM5uWocXZ6wjIzvX63CMMaZcWXI4ARHh4X7t2HEgg7fnbvI6HGOMKVeWHE7ivJZRXNw2mtdnJbP/cLbX4RhjTLmx5FCMv/ZrR3pmDq//YIvyGWOqD0sOxWjfqBZXdYrl7Z83sX3/Ea/DMcaYcmHJwQ8P9G6DKrw0Y53XoRhjTLmw5OCHuHrh/PG8ZkxauJXk1HSvwzHGmDJnycFPI3q1JjzEFuUzxlQPfiUHEeknImtEJFlERhZR311EFolIjogMKlD3jYjsE5EvC5R/4B5zuYiMF5Fgt7yniOwXkd/c1z9O5wOWlnoRIdzVvSXfrtzJws17vQ7HGGPKVLHJQUQCgVFAfyABuEFEEgrstgUYCnxYxCGeA4YUUf4B0A44E6gB3OFTN0dVO7mvx4uLsbzcflEL6tcM5dlptiifMaZq86fn0AVIVtUNqpoFTAQG+u6gqptUdSlQaCEiVf0eKHShXlW/VhfwK9DkVD5AeQoPCeLPl8bz66Y9zFqT6nU4xhhTZvxJDrHAVp/tFLesVLiXk4YA3/gUny8iS0RkmoiccYJ2w0QkSUSS0tLSSiucYg3uHEfzqHCenbaG3DzrPRhjqqaKMCD9OvCjqs5xtxcBzVS1I/Aq8FlRjVR1jKomqmpidHR0OYUKwYEBPNS3LWt2pvPZ4m3ldl5jjClP/iSHbUCcz3YTt+y0ichjQDTwYH6Zqh5Q1YPu+6+BYBGpXxrnKy2XdWjEmbG1eWHGWluUzxhTJfmTHBYA8SLSQkRCgMHA1NM9sYjcAfQFblDVPJ/yhiIi7vsuboxl88zO3GxY8SmUcHA5IEAY2b8d2/Yd4f35m8skNGOM8VKxyUFVc4ARwHRgFfCxqq4QkcdFZACAiHQWkRTgWmC0iKzIby8ic4BJwCUikiIifd2q/wIxwLwCU1YHActFZAnwCjBYy2pq0G8fwKSh8Nk9kF2ypTEuaF2fi+Lr89qsZA5k2KJ8xpiqRarClMzExERNSkoqecO8PPjx3zD7aWjUCa5/H+rEFd/OtXzbfv7w6k+MuLg1D/VtW/LzG2OMh0RkoaomFlVXEQakvRMQAD1HwuAJsGcDjOkBG+cU387VIbY2V3RszLifNpJ6IKMMAzXGmPJVvZNDvnaXwZ0zITwK3h0I89/wexzioT5tyM7N4+XvbVE+Y0zVYckhX/14uON7aNsfvhkJn97l1zhEs6gIbuzalIkLtrIh7WA5BGqMMWXPkoOvsFpw3Xtw8d9h6ccwrg/s21Jss3t7xRMaFMDz364thyCNMabsWXIoKCAAevwFbvwI9m6C0T1gww8nbRIdGcodF7Xkq2XbWbJ1X/nEaYwxZciSw4m06Qt3zoKaDeC9K2Huaycdh7jzohbUiwjh2W9sUT5jTOVnyeFk6reGO76DdpfDt3+DT+6ArMNF7hoZFsy9vVozd/1u5qzbVc6BGmNM6bLkUJzQSGccotf/wvJPnHGIvZuK3PXGrk1pUrcGz0xbTZ4tymeMqcQsOfhDBLo/BDdNgv1bYExPWD+z0G6hQYE81KctK7cf4Iulv5d/nMYYU0osOZREfG9nHCKyEbx/Dfz8cqFxiAEdG9O+US2e/3YtWTmFHm9hjDGVgiWHkopqBbfPgPYDYMY/YPJtkHXoaHVAgPBwv7Zs2XOYCb8WPw3WGGMqIksOpyK0Jlz7Nlz6T1j5GYztDXs2Hq3u0Saa81rW45Xv13EwM8e7OI0x5hRZcjhVInDh/XDTZDiwzRmHSP7OrRJG9m/P7kNZjJ2zwds4jTHmFFhyOF2tL4Fhs6BWLHxwLfz0IqjSKa4O/Ts05M0fN7DrYKbXURpjTIlYcigN9VrCHTMg4Ur47v9g0i2QeZCH+rYlIyeP12Ymex2hMcaUiCWH0hISAYPGQ+8nYNUXMK43rQJ2cl1iHB/8spktu4u+ec4YYyoiSw6lSQQuuA/+OAXSt8ObF/PXVlsIDBCen7HG6+iMMcZvlhzKQquLYdhsqNOUup/exJjmP/D5b9tYvm2/15EZY4xfLDmUlbrN4bZv4cxBdN/6BmPDXuGVaYu9jsoYY/xiyaEshYTD1W9C33/RS5J4aMs9LFq0wOuojDGmWH4lBxHpJyJrRCRZREYWUd9dRBaJSI6IDCpQ942I7BORLwuUtxCRX9xjfiQiIW55qLud7NY3P/WPVwGIwPl/IufGT4gOSKfNFwPRNd94HZUxxpxUsclBRAKBUUB/IAG4QUQSCuy2BRgKfFjEIZ4DhhRR/izwoqq2BvYCt7vltwN73fIX3f0qvZD4i5nbazKbcqNhwmD44d+QZ2svGWMqJn96Dl2AZFXdoKpZwERgoO8OqrpJVZcChb7tVPV7IN23TEQE6AVMdoveAa503w90t3HrL3H3r/T6XdiFkXWeY0ZQD5j1FHw8BDIOeB2WMcYU4k9yiAW2+mynuGWnIwrYp6r5Cw/5HvPo+dz6/e7+xxGRYSKSJCJJaWlppxlO+QgMEO7v15FhB+8kqf3DsGYajL0Edq3zOjRjjDlOpR2QVtUxqpqoqonR0dFeh+O3S9o3ILFZPYYndyHjxilweA+82QtWf+11aMYYc5Q/yWEbEOez3cQtOx27gToiElTEMY+ez62v7e5fJTiL8rUjLT2TcSlNnPsh6rWEj25ynjRnjDEVgD/JYQEQ784uCgEGA1NP56SqqsAsIH9m0y3A5+77qe42bv1Md/8qI7F5PS5tH8N/Z69nb3AM3Po1xJ0Hn9zpLL1hjDEeKzY5uNf9RwDTgVXAx6q6QkQeF5EBACLSWURSgGuB0SKyIr+9iMwBJuEMLKeISF+36mHgQRFJxhlTGOeWjwOi3PIHgUJTZ6uCv/Zry6GsHEbNSnbWZbrpY4g9BybdCmu/9To8Y0w1J1Xhj/LExERNSkryOowS+8ukJXz+2+/MfKgHTeqGw5F98O4ASF3tJIuWPb0O0RhThYnIQlVNLKqu0g5IVwUP9G4DAi/OcGcr1agDQz6DqNbw4WDYPNfbAI0x1ZYlBw81rlODod2aM2VxCqt3uPc7hNeDmz+DOnHOw4O22nIbxpjyZ8nBY/f0bEXN0CD+9fVqcnLdewhrNoCbP4eIaHj/Gvj9N2+DNMZUO5YcPFYnPIQHe7fhx7Vp3DT2F3YeyHAqajWGW6ZCWC147yrYueLkBzLGmFJkyaECuPWCFrxwXUeWpuzn8lfm8HPyLqeiTlMnQQSFwrsDIW2tt4EaY6oNSw4VxNXnNGHqiAuoGx7CH8f9wkvfrSU3T50b5G52byt5dwDs2eBtoMaYasGSQwUSHxPJ5yMu4KpOsbz03TpuGf8raemZEN3GSRA5mfDOANi3xetQjTFVnCWHCiY8JIjnr+vIs9ecyYJNe7j8lTnM37AbYhJgyKfOKq7vDIADv3sdqjGmCrPkUAGJCNd3bspnf7qAmqFB3PjmfEbNSiavYUcYMgUOpTkJ4mCq16EaY6ooSw4VWPtGtZh674VcflZjnpu+htveWcCeumfBTZPgwDZnkPpQlVmT0BhTgVhyqOBqhgbxyuBOPHFlB+Ym7+byV+awkHZwwwTYvR7eu9JZdsMYY0qRJYdKQEQYcl4zptzTjeDAAK4fPZ83U5qi178PqaucG+Uy04s/kDHG+MmSQyXSIbY2X953IZe2j+Gpr1dx57x6HBo4Dn5fDB9cB1mHvA7RGFNFWHKoZGqFBfPGH8/hsSsS+GFtKn2/iWRzz5dh63yYcANkH/E6RGNMFWDJoRISEW69oAWT7u6GKlz6bRRzEv6JbvwRPr7ZuR/CGGNOgyWHSqxTXB2+uu9CerSJZsjCVnzY4AFY9y1Mvg1ys70OzxhTiVlyqOTqhIfw5s2JPHpZO/6R0plXQu6A1V/ClGGQl+t1eMaYSirI6wDM6RMRhnVvxTlN6zLiw1Aycg/z1xUfokEhyMA3IMD+BjDGlIx9a1Qhic3r8dV9F7K8xa28kD0IWTKR7Kn3QxV4FKwxpnxZcqhiomqG8vbQzoReMpI3cgYQ/Ns77PnkQUsQxpgS8Ss5iEg/EVkjIskiMrKI+u4iskhEckRkUIG6W0Rknfu6xS2LFJHffF67ROQlt26oiKT51N1RGh+0OgkIEP7UK55OQ1/kw4A/UG/5eFa/bwnCGOO/YpODiAQCo4D+QAJwg4gkFNhtCzAU+LBA23rAY0BXoAvwmIjUVdV0Ve2U/wI2A1N8mn7kUz/2FD9btXd+6/r0vn8c30VcTrv14/n29fs5kmWD1MaY4vnTc+gCJKvqBlXNAiYCA313UNVNqroUyCvQti8wQ1X3qOpeYAbQz3cHEWkDNADmnOJnMCcRXSuMix98jxUN/kCftLf58Pn7SU61pTaMMSfnT3KIBbb6bKe4Zf7wp+1gnJ6C7zWPa0RkqYhMFpG4og4sIsNEJElEktLS0vwMp3oKDAzkjLvfJbXZFdye+S6TXnuUzxZv8zosY0wFVhEGpAcDE3y2vwCaq+pZOD2Nd4pqpKpjVDVRVROjo6PLIcxKLiCQBje/RUbry3kk4F0WTP4Pj0xZRka2XWYyxhTmT3LYBvj+9d7ELfPHSduKSEcgSFUX5pep6m5VzV//YSxwrp/nMsUJDCZs8NvkxffhqeDxZC98j6ten8vGXbZgnzHmeP4khwVAvIi0EJEQnL/0p/p5/OlAHxGpKyJ1gT5uWb4bOL7XgIg08tkcAKzy81zGH0EhBFz3HrTsyXMhb9Jx3wyuePUnvlq63evIjDEVSLHJQVVzgBE4X+qrgI9VdYWIPC4iAwBEpLOIpADXAqNFZIXbdg/wBE6CWQA87pblu44CyQG4T0RWiMgS4D6cWVCmNAWHweAJSNPzeZrXGFJ7CX/6cBGPfb6czBy7zGSMAdEqMPc9MTFRk5KSvA6j8slMh/euQn//jY9bPc3DyxrTKa4OY29JpH7NUK+jM8aUMRFZqKqJRdVVhAFp45XQSLhpMhJzBtdv+BuTemewescBrnnDxiGMqe4sOVR3NerAkE8hqjWd5/2JqVcI6Rk5XPPGXBZt2et1dMYYj1hyMBBeD27+HOrE0eaHEUy5rQORYUHc+OZ8vl2xw+vojDEesORgHDWj4arRcGgXzZe/xifDu9G2YS3ufn8h787b5HV0xphyZsnBHBN7DpwzBH75L/WPbGbinefRq10D/vH5Cp6etoq8vMo/ecEY4x9LDuZ4vf4BwRHwzcPUCA5g9JBE/nheU0b/sIH7P/rNproaU01YcjDHqxkNPUfC+pmwZhqBAcITAzvwcL92TF3yO7eM/5X9R+z51MZUdZYcTGFd7oT6bWH6I5CdgYgwvGcrXh7ciYWb93Ltf+eybd8Rr6M0xpQhSw6msMBg6P8M7N0E80cdLR7YKZZ3buvC9n0ZXP36z6z4fb93MRpjypQlB1O0Vr2g3R/gx//A/mPrLHZrVZ9Jw88nQITrR89nzjpbLt2YqsiSgzmxPk9CXi5899hxxe0a1mLKPd1oUrcGt761gMkLUzwK0BhTViw5mBOr1wIuuA+WTYIt84+ralS7Bh/ffT5dW9bjoUlLePX7dVSFdbqMMQ5LDubkLnwAasXC139xehE+aoUF89bQLlx9dizPz1jLI1OWkZNb8EmxxpjKyJKDObmQCOj9OOxYCoveLVwdFMDz13VkxMWtmbhgK3e+m8ShzBwPAjXGlCZLDqZ4Ha6Bpt1g5hNwpPBifCLCQ33b8q+rzuSHtWkMHjOf1PQMDwI1xpQWSw6meCLQ/1knMcx+5oS73di1KW/enEhy6kGufn0u69MOlmOQxpjSZMnB+KfRWXDuUPj1Tdi58oS7XdI+honDziMjO5dr3phL0qY9J9zXGFNxWXIw/rv4784Dgr55GE4yM6ljXB2mDL+AuuEh3Dj2F6Yts+dTG1PZWHIw/ouIgl5/h40/wqovTrpr06hwPhnejQ6Na3HPh4sY99PGcgrSGFMa/EoOItJPRNaISLKIjCyivruILBKRHBEZVKDuFhFZ575u8Smf7R7zN/fVwC0PFZGP3HP9IiLNT+8jmlJ17q3Q4AyY/jfIPvn6SvUiQvjwzvPokxDDE1+u5IkvV9qy38ZUEsUmBxEJBEYB/YEE4AYRSSiw2xZgKPBhgbb1gMeArkAX4DERqeuzy02q2sl9pbpltwN7VbU18CLwbIk/lSk7gUHO4PT+LfDzK8XuHhYcyOs3ncvQbs0Z99NG7p2wmIxsW/bbmIrOn55DFyBZVTeoahYwERjou4OqblLVpUDBO6D6AjNUdY+q7gVmAP2KOd9A4B33/WTgEhERP+I05aXFRZBwJfz0IuzbWuzugQHCY1ck8LfL2vPVsu0MGfcL+w5nlUOgxphT5U9yiAV8vwFS3DJ/FNf2LfeS0v/6JICjbVQ1B9gPRPl5PlNe+jzh/Jzxv37tLiLc2b0lr95wNku27ueaN+aydc/hMgzQGHM6vByQvklVzwQucl9DStJYRIaJSJKIJKWl2cqg5a5OU7jwfljxKWyc43ezKzo25r3bu5CWnslVr89lWYot+21MReRPctgGxPlsN3HL/HHCtqqa/zMdZ6yiS8E2IhIE1AZ2Fzywqo5R1URVTYyOjvYzHFOqLvgz1G4K0x6GXP+XzOjaMopPhncjNCiA68fMY9aa1OIbGWPKlT/JYQEQLyItRCQEGAxM9fP404E+IlLXHYjuA0wXkSARqQ8gIsHAH4DlbpupQP6spkHATLXlPium4BrQ90lIXQEL3ypR0/iYSKbc043mURHc8U4SE3/dUkZBGmNORbHJwb3uPwLni34V8LGqrhCRx0VkAICIdBaRFOBaYLSIrHDb7gGewEkwC4DH3bJQnCSxFPgNp7fwpnvKcUCUiCQDDwKFps6aCqT9AGjRHWY+CYdLdjd0TK0wPr77fLq1imLklGW8MGOtLfttTAUhVeEfY2JioiYlJXkdRvW1cyX890JneY0/vFDi5tm5eTw6ZRmTFqYw6NwmPH31mQQH2v2ZxpQ1EVmoqolF1dm/QHP6YhKg8x3OpaUdy0rcPDgwgH8POos/XxLP5IUp3Pb2AtIzsssgUGOMvyw5mNJx8SMQVscZnD6F3qiI8EDvNjx7zZnMXb+bns/N5rWZ69h/2JKEMV6w5GBKR426cMn/wuafYcWUUz7M9Z2bMunu8zmrSW3+8+1aLnh2Jk9/vYqdB+z5EMaUJxtzMKUnLxfG9HAGpkcscJ4idxpW/n6A//6wni+X/k5QQADXnBvLsO6taFH/9I5rjHHYmIMpHwGB0P85OLANfnrptA+X0LgWr9xwNrMfupjrOjfhk0Xb6PX8bP70wSKWb7Ob54wpS9ZzMKXvkztg5VQY8SvUbV5qh01Nz+Ctnzfx/rzNpGfmcFF8fYb3bMX5LaOw5beMKbmT9RwsOZjSt38bvJYIrXrB4A9K/fAHMrL5YP4Wxv20kV0HM+kYV4d7eraid/sYAgIsSRjjL7usZMpX7Vi46H9g9ZewflapH75WWDDDe7bip4cv5skrO7D3UBZ3vbeQ3i/+wKSkrWTlFFwc2BhTUtZzMGUjOwNe7wpBYXD3TxAYXGanysnN4+vlO3hj9npWbT9Ao9ph3HFRSwZ3jiMiNKjMzmtMZWc9B1P+gsOg778gbTUsGFumpwoKDGBAx8Z8fd+FvHVrZ+LqhfPElyu54NmZvPTdWvYesmdHGFNS1nMwZUcV3r8aUhbCfYsgon65nXrh5j28MXs9361KpUZwIDd0acodF7WgcZ0a5RaDMRWdDUgb76StgTe6QaebYEDxjxUtbWt2pDP6h/V8vuR3AgSu7BTLXT1a0bpBzXKPxZiKxpKD8db0v8G8UTBsFjQ+25MQtu45zNg5G5i4YCtZuXn0SYhheM/WdIqr40k8xlQElhyMtzL2w6vnQr2WcNt08PCehF0HM3ln7ibembuJAxk5dGsVxfCerbiwdX27V8JUOzYgbbwVVhsueQy2/gLLJnkaSv2aofxPn7bMfeQSHr2sHcmpBxky7leueO0nvlq6ndy8ivPHkqqSkZ3LgYxse86FKXfWczDlIy8PxvaCA9vh3iQIjfQ6IgAyc3L5dNE2Rv+4gY27DtE8Kpy7erTi6nNiCQ0KPKVjZuXkcSgzh4MFXxk5R8vTfd771ue/z6/LznX+fUaGBdEquqbzahDhvo+gab0IQoLsbzxzauyykqkYti6AcZfChQ/Apf/ndTTHyc1Tpq/Yweuzk1m+7QANIkO57cIWxNUN51BmDumZJ/lizzj2hZ6emeP3TXgRIYFEhAZRMyyImqEFXmFBTl1oECGBAWzZc5gNuw6yPvUQO3xWqA0MEJrVC6dlgaTRKromdcJDyurXZaoISw6m4vj0blj+CdwzH6JaeR1NIarKT8m7eGP2euau312oPiw4gJqhwdQMDSz0pZ7/RR8ZeuyLvWbBL3/3Sz8iJIjAU1zqIz0jm427DrE+zUkW69MOsj7tIJt2HSYr91hiiooIOa6n0dJNGk3qhp/yuU3VYsnBVBzpO5zB6eYXwY0TvY7mpDakHSQ7V4kIDSQyNJiI0ECCKvDjS3PzlJS9hwsljfVph9jjcyNgSFAALaIiCiWNltE1qWl3lFcrJ0sO9n+CKV+RDaHHX2HGP2DdDIjv7XVEJ9QyunLdCxEYIDSLiqBZVAS92h1ft/dQ1tHLUvlJY9X2dKav2HncIHzDWmHHkkb9CFo1cMY5GtUOs9lc1YxfPQcR6Qe8DAQCY1X1mQL13YGXgLOAwao62afuFuDv7uaTqvqOiIQDk4BWQC7whaqOdPcfCjwHbHPbvKaqJ11/wXoOlUxOFrx+njOldfg8CLJr417Jysljy55DJBfoaWxIPUh6Zs7R/cJDAmkZHUF8g0haN6hJfIOaxMdEEle3RoXuTZmTO62eg4gEAqOA3kAKsEBEpqrqSp/dtgBDgYcKtK0HPAYkAgosFJGpQCbwH1WdJSIhwPci0l9Vp7lNP1LVESX5kKYSCQqBfs/Ah9fCr6Oh271eR1RthQQF0LpBJK0bHD97TFVJS88kOe0gG9KcxJGcepD5G3bz6eJtx7VvWT/CTRiRxMc4iaNZlM2iquz8uazUBUhW1Q0AIjIRGAgcTQ6qusmtKzhNoy8wQ1X3uPUzgH6qOgGY5bbNEpFFQJPT+yimUmnTB+L7wuxn4czrIDLG64iMDxGhQa0wGtQKo1ur49fESs/IJjn14NHXutSDLEnZx5dLtx/dJyhAaF4/wulhNKhJ65hI4hvUpEX9CMKCT22KsClf/iSHWGCrz3YK0NXP4xfVNtZ3BxGpA1yBc9kq3zXupaq1wAOq6nsMU1X0expGdYXv/wlXvu51NMZPkWHBnN20Lmc3rXtc+eGsHDakHWJdajrrdjpJY/WOdKav2EH+sEaAQNN64bT26WXEN4ikVYMIwkNsCLQi8fS/hogEAROAV/J7JsAXwARVzRSRu4B3gF5FtB0GDANo2rRpOUVsSlVUKzj/Hvj5ZUi8HZqc63VE5jSEhwTRIbY2HWJrH1eekZ3Lpt2HjiaMZDd5zF6TSo7PYHiTujWOjmXkj2u0blCTyLCyexaIOTF/ksM2IM5nuwnHBov9aduzQNvZPttjgHWqevRp9KrqO7l8LPDvog6sqmPc9iQmJlb++bjVVfe/wJKJMO0vcPt3EGDXqauasOBA2jWsRbuGtY4rz87NY7NP0liXepB1O9P5ef3u424kbFQ7jDkPkDYAABFaSURBVNZuoohvEMmZsbU5o3EteyRsGfMnOSwA4kWkBc6X/WDgRj+PPx34l4jk9z/7AI8AiMiTQG3gDt8GItJIVfMvXg4AVvl5LlMZhUZC78fh07tgyQQ4+yavIzLlJDjw2GB4f5/y3Dxl657DbsJIJ9lNHhN/3cqR7FwAYmqFcmn7GC5NiKFbq6hTXurEnJi/U1kvw5mqGgiMV9WnRORxIElVp4pIZ+BToC6QAexQ1TPctrcBj7qHekpV3xKRJjhjEatxZi6BO2VVRJ7GSQo5wB5guKquPll8NpW1ksvLg/F9YO9muHchhNUqvo2pdvLylG37jvDrxj3MWLmTH9elcTgrl4iQQHq0jaZ3Qgy92sZQO9wuQ/nL7pA2Fd+2hfDmJdBtBPR50utoTCWQkZ3LvPW7+XblTr5btZO09EwCA4QuzevROyGG3gkxxNUL9zrMCs2Sg6kcPh/hXFoaPg+i23gdjalE8vKUJSn7mLFyJzNW7mRd6kEA2jWMpE9CDL0TGtIhtpbd5V2AJQdTORxMg1fPgbgucNNkTx8KZCq3TbsOHU0USZv3kKfO0iCXJjSgd0JDzm8ZZTfpYcnBVCbzRsH0R+HSf8IZV0GdppYkzGnZcyiL71c5iWLOul0cyc6lZmgQPdpG0ychhp5tG1C7RvUcp7DkYCqP3GwY39cZgwCo1QSadXNfF0D9eEsW5pRlZOfyc/IuZrjjFLsOZhEUIHRtWY/e7uynJnWrzziFJQdTueTlQepK2DIPNv8Mm36GQ6lOXXj9Y4miWTeIOQMCbBqjKbm8PGXx1vxxih2sTzsEQEKjWkcHtM9oXLXHKSw5mMpNFfZscBLF5rnOz31bnLrQ2tD0vGMJo1FHW+XVnJINaQePjlMs3LIXVWhcO4xL3UTRtUXVG6ew5GCqnn1bj/UsNs+FXWud8uBwaJJ4rGcRmwgh1ecygSkduw5mMnNVKjNW7WTOujQysvOIDAuiZ9sG9E6IoWfbaGqVcFkPVSU3T8lVJS8Pct3tvKNl6lPmU5/fzue989O5YbBxnTCaRUWc0ue05GCqvoNpsGXusZ7FjuWAQkAwxJ5zrGcR1wXCahd7OGPyHcnK5afkXcxYuYPvV6Wy+1AWwYFCo9o1ivjCzn+PTyJwfpbVV+3dPVoxsn+74ncsgiUHU/0c2Qdbf3GTxVz4fRHk5YAEQMMzj/Usmp4PEfWLP54xOF/4i7fsZcaqnaQeyCRAhMAA5yl8ASLuthwtDwgQAo8rK1BfqMzZPyCgQH1+Wf6xjpZBkzrhNI06td6xJQdjsg5BStKxnkXKAsjJcOqi2x3rWTQ9H2rHnvxYxlQR9gxpY0IioGUP5wWQkwm//3ZszGLpJEga79TVbQ5NuzkD3TXqAgqa5wyMq7ta6NH3PnWF9vOt4yR1RbXTY3UBgdCok10SM+XKeg7GAOTlwo5lx3oWm+fCkT1eR3U8CYCYDsfu+2jaDWpGex2VqcTsspIxJZU/fTb7sPOljDg/RY5/X3D7uLqi2slJ6gq2c99nH3YuieXPztq6AHKOOHFGtT6WKJp1szvKTYnYZSVjSkrEeVJdRVDoklgWbF/izs6aBys/h0XvOnW1Yp1xk/zeRf229gAlc0qs52BMZZeXB2mrjs3M2jIP0t3nZdWo6/Yqznd+NjoLAqvnOkKmMOs5GFOVBQQ4y4jEnAFd7nQuie3d6PQq8u/9WPOVs29wBMR1PjYzq0kiBNfwNn5TIVlyMKaqEYF6LZ1X/mNX03cc61Vsngez/sVxNwnmX4qK6wo16ngavqkY7LKSMdVRoZsEF0NeNiDujKjzjw10R8Z4Ha0pIzZbyRhzclmHYVvSsUtRW391ZkmB0wNp1g1a9ID2AyA4zNtYTamx5GCMKZncbNi+9NiYxZZ5cGQvRERDl7ug8+0QXs/rKM1pOlly8GuOm4j0E5E1IpIsIiOLqO8uIotEJEdEBhWou0VE1rmvW3zKzxWRZe4xXxF30XQRqSciM9z9Z4hI3ZJ9XGPMaQsMhibnQrd74YYJ8JcNcPPnzp3as56EFxLgywdh93qvIzVlpNjkICKBwCigP5AA3CAiCQV22wIMBT4s0LYe8BjQFegCPObzZf8GcCcQ7776ueUjge9VNR743t02xngpIABa9oQ/ToZ75sOZ18Di9+DVc2HiTbBlPmW27KjxhD89hy5AsqpuUNUsYCIw0HcHVd2kqkuBvAJt+wIzVHWPqu4FZgD9RKQRUEtV56tzXetd4Eq3zUDgHff9Oz7lxpiKoEF7GDgK7l8O3R9y7toe3xfGXgorPnOWIjGVnj/JIRbY6rOd4pb540RtY933RR0zRlXdO3jYAdhUCWMqosgY6PV3eGAFXPYfOLwbJt0Cr5wNv4yGzINeR2hOQ4W+r97tVRTZVxWRYSKSJCJJaWlp5RyZMeaokAjn5rt7F8L170NkQ5j2V3gxAb77p3OPhal0/EkO24A4n+0mbpk/TtR2m/u+qGPudC874f5MLerAqjpGVRNVNTE62lamNMZzAYHQ/gq4/Vu4fYYz9fXnl+DFDvDZPbBzhdcRmhLwJzksAOJFpIWIhACDgal+Hn860EdE6roD0X2A6e5lowMicp47S+lm4HO3zVQgf1bTLT7lxpjKIq4LXP8e3LsIEm+DFZ/CG93gvatg/UwbvK4E/LrPQUQuA14CAoHxqvqUiDwOJKnqVBHpDHwK1AUygB2qeobb9jbgUfdQT6nqW255IvA2UAOYBtyrqioiUcDHQFNgM3Cdqp50YX27z8GYCu7wHudhSr+OgYM7nbuwzx8BHa6BoBCvo6u27CY4Y0zFkJMJyybDvNcgdSVENoKud8G5Q92n7pnydNo3wRljTKkICnUWAxw+F/74CUS3he/+D144A6Y9DHs3eR2hcdmqrMaY8icCrS91XjuWwdzXYMFY57JT+wHQ7T7nDm3jGes5GGO81fBMuHo03L/MSQrrZ8HYXjC+H6z+ynmYkSl3lhyMMRVDrcbQ+5/w4Aro9wzs3wYTb4TXEmHBOGflWFNuLDkYYyqW0Eg4bzjctxgGvQVhteGrB+HFM2DmU3DQbnotD5YcjDEVU2AQdLga7pwJt05znlb343Pw0pnw7d/h0C6vI6zSbEDaGFOxiTgPG2rWDXatgx//A/NGQdJbzjTYbvfaNNgyYD0HY0zlUT/eGby+Zz7E94E5z8NLZ8HsZyBjv9fRVSmWHIwxlU90W7j2Lbj7Z2jRHWY/7SSJOc/barClxJKDMabyatgBBn8Aw2Y76zl9/zi83BHmvgrZR7yOrlKz5GCMqfwanw03TXJWg23oDli/3NF5rkROptfRVUqWHIwxVUdcF7j5Mxj6NUS1dp4r8crZzqJ/OVleR1e6cjJh3XdlthS6JQdjTNXT/AIY+hUM+cy5ue7LB+C1c2Hx+5Cb43V0p+7IPlg6CSYNhX+3gg+ucWZtlQFbldUYU7WpwroZMOsp2P4b1GsFPUc6y4UHBHodXfH2p8CaabD6S9j0E+TlQEQDaNsf2l3uPFQpOOyUDm1LdhtjjKqzVtOsf0HqCohu5ySJ9gMhoAJdRFF1ljNf/ZXz2v6bUx4V7ySDdpdDbGKpxGzJwRhj8uXlwcrPnOmvu9ZCzJlw8SPQ9jLnhjsv5ObA1vnHEsK+zYBAk87Q7jJoezlEtyn101pyMMaYgvJynQcP/fAM7NngzHi6+G/OMuLlkSSyDjmPTF39Naz9Bo7sgcBQaNnD6R206Q+RMWUawsmSgy2fYYypngICoeP1ztjDkgnww7/hg0EQ1xUuftS5ll/aSeJgmpMIVn8FG2ZBTgaE1YE2fZ2eS+tLnIUHKwDrORhjDDhTXRe/56zdlP47NLsQev3NWdPpdOxe7ySDNV/DlvmAQu04p3fQ9jLn+IHBpfIRSsouKxljjL+yM2Dh285SHIdSoeXF0Ovv0KTI79DC8vLg98XO7KI1X0Paaqe84ZnO2EG7y533Xo1v+Djt5CAi/YCXgUBgrKo+U6A+FHgXOBfYDVyvqptEJAQYDSQCecCfVXW2iEQCc3wO0QR4X1XvF5GhwHPANrfuNVUde7L4LDkYY0pd1mHn0aU/vwSHd0N8X+dyU+NOhffNyYSNc2DNV84YwsEdIIFOr6DdH5xpp3Wblf9nKMZpjTmISCAwCugNpAALRGSqqq702e12YK+qthaRwcCzwPXAnQCqeqaINACmiUhnVU0HOvmcYyEwxed4H6nqiBJ9SmOMKU0h4XDBfZB4q7MMx9xXYEwP58v+4kehViwkf+f0ENZ9B1npEBzhjBu0u9xZNTa8ntef4pT5MyDdBUhW1Q0AIjIRGAj4JoeBwP+57ycDr4mIAAnATABVTRWRfTi9iF/zG4pIG6ABx/ckjDGmYgiNhO4PQZc7Yd7rzrMkVn/lDGjn35DW4erTviGtovEnOcQCW322U4CuJ9pHVXNEZD8QBSwBBojIBCAO57JTHD7JARiM01Pwvb51jYh0B9YCD6iq7/mNMab8hdV27ofoehf8OsZZ9bUUb0iraMp6Kut4oD2QBGwG5gK5BfYZDAzx2f4CmKCqmSJyF/AO0KvggUVkGDAMoGnTpqUfuTHGFCW8nnNndRXnT7rbhvPXfr4mHBssLrSPiAQBtYHdqpqjqg+oaidVHQjUwekN4O7bEQhS1YX5Zaq6W1Xz19gdi9PbKERVx6hqoqomRkdH+/ExjDHG+Muf5LAAiBeRFu7so8HA1AL7TAVucd8PAmaqqopIuIhEAIhIbyCnwED2DcAE3wOJSCOfzQHAKr8/jTHGmFJR7GUldwxhBDAdZyrreFVdISKPA0mqOhUYB7wnIsnAHpwEAs5A83QRycPpXQwpcPjrgMsKlN0nIgOAHPdYQ0/pkxljjDlldhOcMcZUUye7z6HqDbEbY4w5bZYcjDHGFGLJwRhjTCGWHIwxxhRSJQakRSQN5ya7U1Ef2FWK4VR29vs4nv0+jrHfxfGqwu+jmaoWeaNYlUgOp0NEkk40Wl8d2e/jePb7OMZ+F8er6r8Pu6xkjDGmEEsOxhhjCrHkAGO8DqCCsd/H8ez3cYz9Lo5XpX8f1X7MwRhjTGHWczDGGFOIJQdjjDGFVOvkICL9RGSNiCSLSNV/esdJiEiciMwSkZUiskJE/ux1TF4TkUARWSwiX3odi9dEpI6ITBaR1SKySkTO9zomr4jIA+6/keUiMkFEqsZzQQuotslBRAKBUUB/nGdd3yAiCd5G5akc4H9UNQE4D/hTNf99APwZe55IvpeBb1S1HdCRavp7EZFY4D4gUVU74DzGYPDJW1VO1TY5AF2AZFXdoKpZwERgoMcxeUZVt6vqIvd9Os4//lhvo/KOiDQBLsd5GmG1JiK1ge44z21BVbNUdZ+3UXkqCKjhPvUyHPjd43jKRHVODrHAVp/tFKrxl6EvEWkOnA384m0knnoJ+CuQ53UgFUALIA14y73MNjb/CY/VjapuA/4DbAG2A/tV9Vtvoyob1Tk5mCKISE3gE+B+VT3gdTxeEJE/AKm+zzav5oKAc4A3VPVs4BBQLcfoRKQuzhWGFkBjIEJE/uhtVGWjOieHbUCcz3YTt6zaEpFgnMTwgapO8ToeD10ADBCRTTiXG3uJyPvehuSpFCBFVfN7kpNxkkV1dCmwUVXTVDUbmAJ08zimMlGdk8MCIF5EWohICM6g0lSPY/KMiAjONeVVqvqC1/F4SVUfUdUmqtoc5/+LmapaJf869Ieq7gC2ikhbt+gSYKWHIXlpC3CeiIS7/2YuoYoOzgd5HYBXVDVHREYA03FmHIxX1RUeh+WlC4AhwDIR+c0te1RVv/YwJlNx3At84P4htQG41eN4PKGqv4jIZGARzgy/xVTRZTRs+QxjjDGFVOfLSsYYY07AkoMxxphCLDkYY4wpxJKDMcaYQiw5GGOMKcSSgzHGmEIsORhjjCnk/wHKKXG+oyobhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model-combined-lstm1.pth')\n",
    "plt.plot(master_train_loss[:], label='train')\n",
    "plt.plot(master_valid_loss[:], label='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study Level Metrics\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyLevelDataset2(torch.utils.data.Dataset):\n",
    "    \"\"\"Kaggle PE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, stage):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.pedataframe = pd.read_csv(csv_file)\n",
    "        \n",
    "        #self.hdf5_filename = '/scratch/features.hdf5'\n",
    "        self.hdf5_filename1 = '/scratch/efficientb0_features.hdf5'\n",
    "        self.hdf5_filename2 = '/scratch/resnet_features.hdf5'\n",
    "        \n",
    "        self._generate_row_indices_list()\n",
    "        \n",
    "        self.stage = stage\n",
    "        \n",
    "        if self.stage == 'train':\n",
    "            self.start = 0\n",
    "            self.end = 2650\n",
    "        else:\n",
    "            self.start = 2660\n",
    "            self.end = 3500\n",
    "        \n",
    "        # 0 - 2650 train\n",
    "        # 2660 - 3500 valid\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return number of 2D images. (Each CT slice is an independent image.)\"\"\"\n",
    "        #return len(self.pedataframe)\n",
    "        return self.end - self.start + 1\n",
    "        #return num_pos_samples_per_dataset + num_neg_samples_per_dataset\n",
    "        \n",
    "    def _generate_row_indices_list(self):\n",
    "        # group slice indices into studies\n",
    "        self.row_indices = [] # index into train df for every study\n",
    "        current_study_id = ''\n",
    "\n",
    "        for slice_index in range(len(self.pedataframe)):\n",
    "            new_study_id = self.pedataframe.StudyInstanceUID[slice_index]\n",
    "            if new_study_id != current_study_id:\n",
    "                self.row_indices.append(slice_index)\n",
    "                current_study_id = new_study_id\n",
    "            if slice_index % 100000 == 0:\n",
    "                print(slice_index)\n",
    "        \n",
    "    def __getitem__(self, study_index):\n",
    "        '''  '''\n",
    "        study_index = study_index + self.start\n",
    "        \n",
    "        #h5py_file = h5py.File(self.hdf5_filename, \"r\")\n",
    "        h5py_file1 = h5py.File(self.hdf5_filename1, \"r\")\n",
    "        h5py_file2 = h5py.File(self.hdf5_filename2, \"r\")\n",
    "        \n",
    "        start_index = self.row_indices[study_index]\n",
    "        if study_index+1 < len(self.row_indices):\n",
    "            stop_index = self.row_indices[study_index+1]\n",
    "        else:\n",
    "            stop_index = len(self.pedataframe)\n",
    "            \n",
    "        # dim: seq_len x embedding_dim\n",
    "        x = np.ones((stop_index-start_index, 3328)) #1280+2048=3328\n",
    "            \n",
    "        for slice_index in range(start_index, stop_index):\n",
    "            data_identifier = 'tensor(' + str(slice_index) + ')'\n",
    "            #slice_embeddings = h5py_file[data_identifier][:]\n",
    "            slice_embeddings = np.concatenate((h5py_file1[data_identifier][:], h5py_file2[data_identifier][:]),axis=0)\n",
    "            x[slice_index-start_index,:] = slice_embeddings\n",
    "\n",
    "            \n",
    "        y = np.ones(9)\n",
    "            \n",
    "        y[0] =  self.pedataframe.negative_exam_for_pe[start_index]\n",
    "        y[1] = self.pedataframe.rv_lv_ratio_gte_1[start_index]\n",
    "        y[2] = self.pedataframe.rv_lv_ratio_lt_1[start_index]\n",
    "        y[3] = self.pedataframe.leftsided_pe[start_index]\n",
    "        y[4] = self.pedataframe.chronic_pe[start_index]\n",
    "        y[5] = self.pedataframe.rightsided_pe[start_index]\n",
    "        y[6] = self.pedataframe.acute_and_chronic_pe[start_index]\n",
    "        y[7] = self.pedataframe.central_pe[start_index]\n",
    "        y[8] = self.pedataframe.indeterminate[start_index]\n",
    "        \n",
    "        h5py_file1.close()\n",
    "        h5py_file2.close()\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection/'\n",
    "train_csv = data_dir + 'train.csv'\n",
    "train_dir = data_dir + 'train/'\n",
    "train_dataset = StudyLevelDataset2(csv_file=train_csv, stage='train')\n",
    "valid_dataset = StudyLevelDataset2(csv_file=train_csv, stage='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "'''\n",
    "\n",
    "batch_size = 1\n",
    "embedding_dim = 3328  #2048+1280=3328\n",
    "nb_lstm_units = 64 #2048\n",
    "\n",
    "class StudyLevelLSTM(nn.Module):\n",
    "    def __init__(self, nb_layers=1, nb_lstm_units=nb_lstm_units, \n",
    "                 embedding_dim=embedding_dim, batch_size=batch_size):\n",
    "        \n",
    "        super(StudyLevelLSTM, self).__init__()\n",
    "\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.linear = nn.Linear(self.nb_lstm_units, 9)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_h0 = torch.randn(self.nb_layers, self.batch_size, self.nb_lstm_units)\n",
    "        hidden_c0 = torch.randn(self.nb_layers, self.batch_size, self.nb_lstm_units)\n",
    "\n",
    "        hidden_h0 = hidden_h0.to(device)\n",
    "        hidden_c0 = hidden_c0.to(device)\n",
    "\n",
    "        hidden_h0 = Variable(hidden_h0)\n",
    "        hidden_c0 = Variable(hidden_c0)\n",
    "\n",
    "        return (hidden_h0.to(device), hidden_c0.to(device))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # reset the LSTM hidden state. Must be done before you run a new batch. Otherwise the LSTM will treat\n",
    "        # a new batch as a continuation of a sequence\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        batch_size, seq_len, _ = X.size()\n",
    "\n",
    "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        #X = torch.nn.utils.rnn.pack_padded_sequence(x, X_lengths, batch_first=True)\n",
    "\n",
    "        # now run through LSTM\n",
    "        X, self.hidden = self.lstm(X, self.hidden)\n",
    "        \n",
    "        X = self.hidden[0]\n",
    "        X = X.contiguous()\n",
    "        X = X.view(-1, X.shape[2])\n",
    "\n",
    "        # run through actual linear layer\n",
    "        X = self.linear(X)\n",
    "\n",
    "        # I like to reshape for mental sanity so we're back to (batch_size, seq_len, nb_tags)\n",
    "        X = X.view(batch_size, 9)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StudyLevelLSTM(\n",
      "  (lstm): LSTM(3328, 64, batch_first=True)\n",
      "  (linear): Linear(in_features=64, out_features=9, bias=True)\n",
      ")\n",
      "tensor([[-0.0556,  0.0040,  0.0738,  0.0298, -0.1024, -0.0057,  0.1472,  0.1130,\n",
      "         -0.0249]], grad_fn=<ViewBackward>)\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# sanity test\n",
    "\n",
    "model = StudyLevelLSTM()\n",
    "print(model)\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "x,y = train_dataset[1]\n",
    "x = torch.tensor(x)\n",
    "x = x.unsqueeze(0).float()\n",
    "x = x.to(device)\n",
    "\n",
    "pred = model(x)\n",
    "print(pred)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:19:56 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.81994, mean: 0.30827: 100%|██████████| 2651/2651 [06:17<00:00,  7.02it/s]\n",
      "100%|██████████| 841/841 [02:03<00:00,  6.79it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:28:17 2020 Epoch 1, lr: 0.1000000, train loss: 0.30827, valid loss: 0.26646\n",
      "pos loss: 0.85295, neg loss: 0.14832, pos mean: 0.54306, neg mean 0.11677\n",
      "Tue Dec  8 19:28:17 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.83186, mean: 0.27366: 100%|██████████| 2651/2651 [06:15<00:00,  7.06it/s]\n",
      "100%|██████████| 841/841 [01:57<00:00,  7.14it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:36:31 2020 Epoch 2, lr: 0.1000000, train loss: 0.27366, valid loss: 0.25923\n",
      "pos loss: 0.83003, neg loss: 0.14425, pos mean: 0.54735, neg mean 0.11519\n",
      "Tue Dec  8 19:36:31 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.84055, mean: 0.27040: 100%|██████████| 2651/2651 [06:14<00:00,  7.09it/s]\n",
      "100%|██████████| 841/841 [01:58<00:00,  7.10it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:44:43 2020 Epoch 3, lr: 0.1000000, train loss: 0.27040, valid loss: 0.25551\n",
      "pos loss: 0.81304, neg loss: 0.14321, pos mean: 0.56081, neg mean 0.11335\n",
      "Tue Dec  8 19:44:43 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.86529, mean: 0.26817: 100%|██████████| 2651/2651 [06:09<00:00,  7.17it/s]\n",
      "100%|██████████| 841/841 [01:56<00:00,  7.20it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 19:52:50 2020 Epoch 4, lr: 0.1000000, train loss: 0.26817, valid loss: 0.25195\n",
      "pos loss: 0.80600, neg loss: 0.14035, pos mean: 0.56849, neg mean 0.11055\n",
      "Tue Dec  8 19:52:50 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.70024, mean: 0.26796: 100%|██████████| 2651/2651 [06:10<00:00,  7.16it/s]\n",
      "100%|██████████| 841/841 [02:00<00:00,  7.00it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:01:00 2020 Epoch 5, lr: 0.1000000, train loss: 0.26796, valid loss: 0.28286\n",
      "pos loss: 0.81854, neg loss: 0.17496, pos mean: 0.52322, neg mean 0.14166\n",
      "Tue Dec  8 20:01:00 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.75327, mean: 0.26718: 100%|██████████| 2651/2651 [06:11<00:00,  7.14it/s]\n",
      "100%|██████████| 841/841 [01:56<00:00,  7.25it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:09:08 2020 Epoch 6, lr: 0.1000000, train loss: 0.26718, valid loss: 0.25123\n",
      "pos loss: 0.78764, neg loss: 0.14319, pos mean: 0.58159, neg mean 0.11078\n",
      "Tue Dec  8 20:09:08 2020 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.88507, mean: 0.26831: 100%|██████████| 2651/2651 [06:08<00:00,  7.20it/s]\n",
      "100%|██████████| 841/841 [01:56<00:00,  7.21it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:17:13 2020 Epoch 7, lr: 0.1000000, train loss: 0.26831, valid loss: 0.26061\n",
      "pos loss: 0.83268, neg loss: 0.14539, pos mean: 0.54253, neg mean 0.11782\n",
      "Tue Dec  8 20:17:13 2020 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.67710, mean: 0.27247: 100%|██████████| 2651/2651 [06:09<00:00,  7.17it/s]\n",
      "100%|██████████| 841/841 [02:00<00:00,  6.98it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:25:23 2020 Epoch 8, lr: 0.1000000, train loss: 0.27247, valid loss: 0.26286\n",
      "pos loss: 0.81357, neg loss: 0.15194, pos mean: 0.55736, neg mean 0.11853\n",
      "Tue Dec  8 20:25:23 2020 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.77080, mean: 0.26907: 100%|██████████| 2651/2651 [06:10<00:00,  7.15it/s]\n",
      "100%|██████████| 841/841 [01:58<00:00,  7.12it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:33:32 2020 Epoch 9, lr: 0.1000000, train loss: 0.26907, valid loss: 0.25831\n",
      "pos loss: 0.82666, neg loss: 0.14383, pos mean: 0.54478, neg mean 0.11641\n",
      "Tue Dec  8 20:33:32 2020 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.79723, mean: 0.26835: 100%|██████████| 2651/2651 [06:11<00:00,  7.13it/s]\n",
      "100%|██████████| 841/841 [01:58<00:00,  7.08it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:41:43 2020 Epoch 10, lr: 0.1000000, train loss: 0.26835, valid loss: 0.24976\n",
      "pos loss: 0.81756, neg loss: 0.13539, pos mean: 0.56475, neg mean 0.10696\n",
      "Tue Dec  8 20:41:43 2020 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.75187, mean: 0.26511: 100%|██████████| 2651/2651 [06:20<00:00,  6.96it/s]\n",
      "100%|██████████| 841/841 [01:59<00:00,  7.03it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:50:03 2020 Epoch 11, lr: 0.1000000, train loss: 0.26511, valid loss: 0.25418\n",
      "pos loss: 0.81030, neg loss: 0.14217, pos mean: 0.56229, neg mean 0.11240\n",
      "Tue Dec  8 20:50:03 2020 Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.79204, mean: 0.26520: 100%|██████████| 2651/2651 [06:33<00:00,  6.74it/s]\n",
      "100%|██████████| 841/841 [01:58<00:00,  7.08it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 20:58:35 2020 Epoch 12, lr: 0.1000000, train loss: 0.26520, valid loss: 0.24878\n",
      "pos loss: 0.81499, neg loss: 0.13473, pos mean: 0.56885, neg mean 0.10619\n",
      "Tue Dec  8 20:58:35 2020 Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.77189, mean: 0.26429: 100%|██████████| 2651/2651 [06:20<00:00,  6.97it/s]\n",
      "100%|██████████| 841/841 [01:55<00:00,  7.28it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:06:51 2020 Epoch 13, lr: 0.1000000, train loss: 0.26429, valid loss: 0.26648\n",
      "pos loss: 0.86251, neg loss: 0.14642, pos mean: 0.53569, neg mean 0.11662\n",
      "Tue Dec  8 21:06:51 2020 Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.80110, mean: 0.26793: 100%|██████████| 2651/2651 [06:07<00:00,  7.22it/s]\n",
      "100%|██████████| 841/841 [01:56<00:00,  7.25it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:14:54 2020 Epoch 14, lr: 0.1000000, train loss: 0.26793, valid loss: 0.25188\n",
      "pos loss: 0.81395, neg loss: 0.13867, pos mean: 0.56492, neg mean 0.10936\n",
      "Tue Dec  8 21:14:54 2020 Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.81802, mean: 0.26597: 100%|██████████| 2651/2651 [06:18<00:00,  7.00it/s]\n",
      "100%|██████████| 841/841 [02:12<00:00,  6.33it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:23:26 2020 Epoch 15, lr: 0.1000000, train loss: 0.26597, valid loss: 0.25666\n",
      "pos loss: 0.83718, neg loss: 0.13973, pos mean: 0.55543, neg mean 0.11091\n",
      "Tue Dec  8 21:23:26 2020 Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.75667, mean: 0.26385: 100%|██████████| 2651/2651 [06:51<00:00,  6.44it/s]\n",
      "100%|██████████| 841/841 [02:09<00:00,  6.49it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:32:27 2020 Epoch 16, lr: 0.1000000, train loss: 0.26385, valid loss: 0.25196\n",
      "pos loss: 0.81990, neg loss: 0.13756, pos mean: 0.56576, neg mean 0.10902\n",
      "Tue Dec  8 21:32:27 2020 Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.77314, mean: 0.26514: 100%|██████████| 2651/2651 [06:54<00:00,  6.40it/s]\n",
      "100%|██████████| 841/841 [02:13<00:00,  6.30it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:41:35 2020 Epoch 17, lr: 0.1000000, train loss: 0.26514, valid loss: 0.25355\n",
      "pos loss: 0.83020, neg loss: 0.13740, pos mean: 0.55666, neg mean 0.10910\n",
      "Tue Dec  8 21:41:35 2020 Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.79086, mean: 0.26672: 100%|██████████| 2651/2651 [06:56<00:00,  6.37it/s]\n",
      "100%|██████████| 841/841 [02:10<00:00,  6.45it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:50:41 2020 Epoch 18, lr: 0.1000000, train loss: 0.26672, valid loss: 0.25102\n",
      "pos loss: 0.81798, neg loss: 0.13682, pos mean: 0.56785, neg mean 0.10749\n",
      "Tue Dec  8 21:50:41 2020 Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.74905, mean: 0.26474: 100%|██████████| 2651/2651 [06:57<00:00,  6.35it/s]\n",
      "100%|██████████| 841/841 [02:11<00:00,  6.38it/s]\n",
      "  0%|          | 0/2651 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 21:59:51 2020 Epoch 19, lr: 0.1000000, train loss: 0.26474, valid loss: 0.25384\n",
      "pos loss: 0.80747, neg loss: 0.14232, pos mean: 0.57403, neg mean 0.11027\n",
      "Tue Dec  8 21:59:51 2020 Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.78854, mean: 0.26436: 100%|██████████| 2651/2651 [06:56<00:00,  6.36it/s]\n",
      "100%|██████████| 841/841 [02:11<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  8 22:08:59 2020 Epoch 20, lr: 0.1000000, train loss: 0.26436, valid loss: 0.25058\n",
      "pos loss: 0.82251, neg loss: 0.13538, pos mean: 0.56769, neg mean 0.10584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bce = torch.nn.BCEWithLogitsLoss()\n",
    "def criterion(logits, target):\n",
    "    loss = bce(logits.view(-1), target.view(-1))\n",
    "    return loss\n",
    "\n",
    "def train_epoch(model, loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward pass\n",
    "        logits = model(data.float())\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        # backpropagate the loss (backward pass)\n",
    "        loss.backward()\n",
    " \n",
    "        # update parameters based on accumulated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "        train_loss.append(loss_np)\n",
    "        average_loss = sum(train_loss) / len(train_loss)\n",
    "        bar.set_description('loss: %.5f, mean: %.5f' % (loss_np, average_loss))\n",
    "\n",
    "    return float(average_loss)\n",
    "\n",
    "def valid_epoch(model, loader):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    pos_logits = []\n",
    "    neg_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data.float())\n",
    "\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "            val_loss.append(float(loss_np))\n",
    "\n",
    "            logits = logits.squeeze()\n",
    "            target = target.squeeze()\n",
    "            \n",
    "            for i in range(logits.shape[-1]):\n",
    "                b = target[i].detach().cpu().numpy()\n",
    "                if b == 1:\n",
    "                    pos_logits.append(float(logits[i].detach().cpu().numpy()))\n",
    "                else:\n",
    "                    neg_logits.append(float(logits[i].detach().cpu().numpy()))\n",
    "                    \n",
    "    val_loss_mean = sum(val_loss) / len(val_loss)\n",
    "    \n",
    "    neg_logits_tensor = torch.FloatTensor(neg_logits).cuda()\n",
    "    pos_logits_tensor = torch.FloatTensor(pos_logits).cuda()\n",
    "    \n",
    "    neg_loss = criterion(neg_logits_tensor, torch.zeros(neg_logits_tensor.shape).float().cuda())\n",
    "    pos_loss = criterion(pos_logits_tensor, torch.ones(pos_logits_tensor.shape).float().cuda())\n",
    "    \n",
    "    neg_loss = neg_loss.detach().cpu().numpy()\n",
    "    pos_loss = pos_loss.detach().cpu().numpy()\n",
    "    \n",
    "    neg_mean = float(torch.sigmoid(neg_logits_tensor).mean().detach().cpu().numpy())\n",
    "    pos_mean = float(torch.sigmoid(pos_logits_tensor).mean().detach().cpu().numpy())\n",
    "    \n",
    "    return float(val_loss_mean), float(pos_loss), float(neg_loss), pos_mean, neg_mean\n",
    "\n",
    "def get_optimizer(lr, model):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "    return optimizer\n",
    "\n",
    "init_lr = 0.1\n",
    "n_epochs = 20\n",
    "device = 'cuda'\n",
    "\n",
    "# reduce LR by gamma three times every 10 epochs\n",
    "# each epoch is 100,000 samples\n",
    "#gamma = 10\n",
    "#schedule = [10, 20, 30]\n",
    "\n",
    "#model = resnext101.to(device)\n",
    "optimizer = get_optimizer(init_lr, model)\n",
    "model.to(device)\n",
    "\n",
    "master_train_loss = []\n",
    "master_valid_loss = []\n",
    "epoch = 1\n",
    "#best_valid_loss = 10\n",
    "\n",
    "\n",
    "while epoch <= n_epochs:\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "    \n",
    "    # update learning rate \n",
    "    #if epoch in schedule:\n",
    "    #    new_lr = optimizer.param_groups[0][\"lr\"] / gamma\n",
    "     #   optimizer = get_optimizer(new_lr, model)\n",
    "    \n",
    "    #train_loader, valid_loader = get_loaders(epoch)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,num_workers=1)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1,num_workers=1)\n",
    "\n",
    "    # train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # validate\n",
    "    valid_loss, pos_loss, neg_loss, pos_mean, neg_mean = valid_epoch(model, valid_loader)\n",
    "    #valid_loss = 0\n",
    "    #pos_loss  = 0\n",
    "    #neg_loss = 0\n",
    "    #pos_mean = 0\n",
    "    #neg_mean = 0\n",
    "    \n",
    "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(valid_loss):.5f}'\n",
    "    print(content)\n",
    "    content = f'pos loss: {(pos_loss):.5f}, neg loss: {(neg_loss):.5f}, pos mean: {(pos_mean):.5f}, neg mean {(neg_mean):.5f}'\n",
    "    print(content)\n",
    "    master_train_loss.append(train_loss)\n",
    "    master_valid_loss.append(valid_loss)\n",
    "    \n",
    "    # save loss data and model weights\n",
    "    #with open('train_loss.pkl', 'wb') as f:\n",
    "        #pickle.dump(master_train_loss, f)\n",
    "    #with open('valid_loss.pkl', 'wb') as f:\n",
    "        #pickle.dump(master_valid_loss, f)\n",
    "        \n",
    "        #torch.save(model.state_dict(), 'model-resnext-50-{}.pth'.format(epoch))\n",
    "        #best_valid_loss = valid_loss\n",
    "    \n",
    "    epoch += 1\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b6a6b37ac50>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model-combined-lstm2.pth')\n",
    "plt.plot(master_train_loss[:], label='train')\n",
    "plt.plot(master_valid_loss[:], label='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_loss.pkl', 'wb') as f:\n",
    "    pickle.dump(master_train_loss, f)\n",
    "with open('valid_loss.pkl', 'wb') as f:\n",
    "    pickle.dump(master_valid_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
