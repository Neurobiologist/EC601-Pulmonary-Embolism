{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import glob\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.color import gray2rgb\n",
    "import functools\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import PIL\n",
    "import json\n",
    "\n",
    "total_preprocess_time = 0\n",
    "\n",
    "class KagglePEDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Kaggle PE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.pedataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.total_preprocess_time = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return number of 2D images. (Each CT slice is an independent image.)\"\"\"\n",
    "        return len(self.pedataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a = time.perf_counter()\n",
    "\n",
    "    \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.pedataframe.StudyInstanceUID[idx],\n",
    "                                self.pedataframe.SeriesInstanceUID[idx],\n",
    "                                self.pedataframe.SOPInstanceUID[idx] + '.jpg')\n",
    "        jpeg_image = PIL.Image.open(img_name) \n",
    "\n",
    "        # image is 256x256 RGB PIL image\n",
    "        # pe_present_on_image is 0 or 1\n",
    "        sample = {'image': jpeg_image, \n",
    "                  'pe_present_on_image': int(self.pedataframe.pe_present_on_image[idx])}\n",
    "\n",
    "        # Only apply transform to image.\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "        b = time.perf_counter()\n",
    "        self.total_preprocess_time += b-a\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection-265-jpeg/'\n",
    "data_dir = '/scratch/rsna-str-pulmonary-embolism-detection-265-jpeg/'\n",
    "train_csv = data_dir + 'train.csv'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "#resnext101 = models.resnext101_32x8d(pretrained=True, progress=True)\n",
    "resnext50 = models.resnext50_32x4d(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use values from sample image (but ideally this should be values from entire dataset)\n",
    "global_mean = 111.6126708984375\n",
    "global_std = 79.95233637352047\n",
    "\n",
    "transform=T.Compose([T.Resize(256),\n",
    "                     T.RandomCrop(224),\n",
    "                     T.ToTensor(),\n",
    "                     T.Normalize(mean=[global_mean, global_mean, global_mean], \n",
    "                                          std=[global_std, global_std, global_std]),\n",
    "                    ])\n",
    "\n",
    "transformed_dataset = KagglePEDataset(csv_file=train_csv, root_dir=train_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnext101.fc = torch.nn.Linear(resnext101.fc.in_features, 2)\n",
    "resnext50.fc = torch.nn.Linear(resnext50.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire dataset:\n",
      "0    0.946085\n",
      "1    0.053915\n",
      "Name: pe_present_on_image, dtype: float64\n",
      "Training split:\n",
      "0    0.946049\n",
      "1    0.053951\n",
      "Name: pe_present_on_image, dtype: float64\n",
      "Validation split:\n",
      "0    0.94623\n",
      "1    0.05377\n",
      "Name: pe_present_on_image, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "# Be sure that the balance of the data in both sets are the same.\n",
    "# i.e. they both have the same percentage of \n",
    "dataset_size = len(transformed_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "print('Entire dataset:')\n",
    "print(transformed_dataset.pedataframe['pe_present_on_image'].value_counts(normalize=True))\n",
    "\n",
    "print('Training split:')\n",
    "a = transformed_dataset.pedataframe['pe_present_on_image'][train_indices]\n",
    "print(a.value_counts(normalize=True))\n",
    "\n",
    "print('Validation split:')\n",
    "b = transformed_dataset.pedataframe['pe_present_on_image'][val_indices]\n",
    "print(b.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:    40.377032849006355\n",
      "copying data:  10.036276337690651\n",
      "forward:   1.3409062377177179\n",
      "backward:  2.501737538143061\n",
      "update:    12.80019326286856\n",
      "{'learning_rate': 0.1, 'decay': 0.0005, 'momentum': 0.9, 'epoch': 0, 'train_loss': 0.21626071736841695, 'test_loss': 4.4366860065910115e-05, 'test_accuracy': 3.350843351424164e-05}\n",
      "Best accuracy: 0.000034\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.1\n",
    "gamma = 0.5\n",
    "momentum = 0.9\n",
    "decay = 0.0005\n",
    "schedule = [20, 40, 60, 80, 100, 120, 140, 160]\n",
    "ngpu = 1\n",
    "prefetch = 2\n",
    "log = './'\n",
    "save = './snapshots'\n",
    "\n",
    "# Init logger\n",
    "if not os.path.isdir(log):\n",
    "    os.makedirs(log)\n",
    "log = open(os.path.join(log, 'log.txt'), 'w')\n",
    "state = {'learning_rate':learning_rate,'decay':decay,'momentum':momentum}\n",
    "log.write(json.dumps(state) + '\\n')\n",
    "\n",
    "# Init checkpoints\n",
    "if not os.path.isdir(save):\n",
    "    os.makedirs(save)\n",
    "\n",
    "# Init model, criterion, and optimizer\n",
    "#net = resnext101\n",
    "net = resnext50\n",
    "\n",
    "ngpu\n",
    "if ngpu > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(ngpu)))\n",
    "\n",
    "if ngpu > 0:\n",
    "    net.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "                            weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "\n",
    "\n",
    "# train function (forward, backward, update)\n",
    "def train():\n",
    "    forward_time = 0\n",
    "    backward_time = 0\n",
    "    opt_time = 0\n",
    "    net.train()\n",
    "    loss_avg = 0.0\n",
    "    for batch_idx, sample_batched in enumerate(train_loader):\n",
    "        data = sample_batched['image'].cuda()\n",
    "        target = sample_batched['pe_present_on_image'].cuda()\n",
    "\n",
    "        # forward\n",
    "        a = time.perf_counter()\n",
    "        output = net(data.float())\n",
    "        b = time.perf_counter()\n",
    "        if batch_idx != 0:\n",
    "            forward_time = forward_time + b-a\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        a = time.perf_counter()\n",
    "        loss.backward()\n",
    "        b = time.perf_counter()\n",
    "        if batch_idx != 0:\n",
    "            backward_time = backward_time + b-a\n",
    "        \n",
    "        # update parameter weights\n",
    "        a = time.perf_counter()\n",
    "        optimizer.step()\n",
    "        b = time.perf_counter()\n",
    "        if batch_idx != 0:\n",
    "            opt_time += b-a\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.2 + float(loss) * 0.8\n",
    "        \n",
    "        if batch_idx % 100 == 0 and batch_idx != 0:\n",
    "            break\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "    return forward_time,backward_time,opt_time\n",
    "\n",
    "# test function (forward only)\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    for batch_idx, sample_batched in enumerate(validation_loader):\n",
    "        data = torch.autograd.Variable(sample_batched['image'].cuda())\n",
    "        target = torch.autograd.Variable(sample_batched['pe_present_on_image'].cuda())\n",
    "\n",
    "        # forward\n",
    "        output = net(data.float())\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        # accuracy\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += float(pred.eq(target.data).sum())\n",
    "\n",
    "        # test loss average\n",
    "        loss_avg += float(loss)\n",
    "        break\n",
    "\n",
    "    state['test_loss'] = loss_avg / len(validation_loader)\n",
    "    state['test_accuracy'] = correct / len(validation_loader.dataset)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(epochs):\n",
    "    if epoch in schedule:\n",
    "        state['learning_rate'] *= gamma\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['learning_rate']\n",
    "\n",
    "    state['epoch'] = epoch\n",
    "    \n",
    "    import time\n",
    "    transformed_dataset.total_preprocess_time = 0\n",
    "    a = time.perf_counter()\n",
    "    forward_time,backward_time,opt_time = train()\n",
    "    b = time.perf_counter()\n",
    "    print('Total:   ', b-a)\n",
    "    print('copying data: ',transformed_dataset.total_preprocess_time)\n",
    "    print('forward:  ', forward_time)\n",
    "    print('backward: ', backward_time)\n",
    "    print('update:   ', opt_time)\n",
    "    \n",
    "    test()\n",
    "    if state['test_accuracy'] > best_accuracy:\n",
    "        best_accuracy = state['test_accuracy']\n",
    "        torch.save(net.state_dict(), os.path.join(save, 'model.pytorch'))\n",
    "    log.write('%s\\n' % json.dumps(state))\n",
    "    log.flush()\n",
    "    print(state)\n",
    "    print(\"Best accuracy: %f\" % best_accuracy)\n",
    "    break\n",
    "\n",
    "log.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Notes\n",
    "-------------------\n",
    "\n",
    "On the SCC we use either the P100 or V100 GPU. I ran some statistics on the time it takes for these GPUs to go through data.\n",
    "\n",
    "Using P100, maximum batch size is 128. All times in seconds. (ResNeXt 101)\n",
    "\n",
    "```\n",
    "Batch size 16 11 iterations\n",
    "forward:  0.2248323503881693\n",
    "backward: 0.3523418242111802\n",
    "Update:   0.9503787271678448\n",
    "\n",
    "Batch size 32 10 iterations\n",
    "forward:  0.21543853264302015\n",
    "backward: 2.2007115576416254\n",
    "update:   0.11410791240632534\n",
    "\n",
    "Batch size 64 10 iterations\n",
    "forward:  0.6264334414154291\n",
    "backward: 3.5233487030491233\n",
    "update:   0.1149715706706047\n",
    "```\n",
    "\n",
    "Using V100: (ResNeXt 50)\n",
    "```\n",
    "Batch size 64 100 iterations\n",
    "Total:   382.8750657370547\n",
    "copying data: 323.9732520148391\n",
    "forward:  1.3590552804525942\n",
    "backward: 7.181785041000694\n",
    "update:   23.04158006538637\n",
    "```\n",
    "\n",
    "Using V100, ResNeXt 50, with data in /scratch:\n",
    "```\n",
    "Total:    40.377032849006355\n",
    "copying data:  10.036276337690651\n",
    "forward:   1.3409062377177179\n",
    "backward:  2.501737538143061\n",
    "update:    12.80019326286856\n",
    "```\n",
    "\n",
    "Notes:\n",
    "* Must copy data to node before using it to save time.\n",
    "* Even using V100 and batch size 64, and training on ResNeXt-50, ignoring data copying time, we still have 30 seconds per 100 iterations. We have 1,800,000 images.\n",
    "\n",
    "1800000/64/100/3600*30 = 2.34375 hours per epoch.\n",
    "\n",
    "Adding in the data copying time, we can expect 3 hours per epoch. This would take forever."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
