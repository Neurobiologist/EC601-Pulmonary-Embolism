{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from skimage.color import gray2rgb\n",
    "import functools\n",
    "from tqdm.auto import tqdm\n",
    "import pydicom\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import PIL\n",
    "import json\n",
    "\n",
    "class KagglePEDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Kaggle PE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.pedataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return number of 2D images. (Each CT slice is an independent image.)\"\"\"\n",
    "        return len(self.pedataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.pedataframe.StudyInstanceUID[idx],\n",
    "                                self.pedataframe.SeriesInstanceUID[idx],\n",
    "                                self.pedataframe.SOPInstanceUID[idx] + '.dcm')\n",
    "        dicom_image = pydicom.dcmread(img_name) \n",
    "        image = dicom_image.pixel_array\n",
    "        \n",
    "        # in OSIC we find outside-scanner-regions with raw-values of -2000. \n",
    "        # Let's threshold between air (0) and this default (-2000) using -1000\n",
    "        image[image <= -1000] = 0\n",
    "        \n",
    "        # convert to HU using DICOM information\n",
    "        # HU is a number between -1000 and 1000 (generally)\n",
    "        # good lung tissue is between -950 and -700 (approximately)\n",
    "        intercept = dicom_image.RescaleIntercept\n",
    "        slope = dicom_image.RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image = slope * image.astype(np.float64)\n",
    "            \n",
    "        image = image.astype(np.int16)\n",
    "        image += np.int16(intercept)\n",
    "        \n",
    "        # Convert image from numpy array to PIL image (so that we can use pytorch transforms)\n",
    "        image[image >= 500] = 500\n",
    "        image[image <= -1000] = -1000\n",
    "        image = (image + 1000)/1500\n",
    "        image = image*255\n",
    "        image = np.uint8(image)\n",
    "        image = PIL.Image.fromarray(image).convert('RGB')\n",
    "\n",
    "        # image is 512x512 RGB PIL image\n",
    "        # pe_present_on_image is 0 or 1\n",
    "        sample = {'image': image, \n",
    "                  'pe_present_on_image': int(self.pedataframe.pe_present_on_image[idx])}\n",
    "\n",
    "        # Only apply transform to image.\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection/'\n",
    "train_csv = data_dir + 'train.csv'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "resnext101 = models.resnext101_32x8d(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use values from sample image (but ideally this should be values from entire dataset)\n",
    "global_mean = 111.6126708984375\n",
    "global_std = 79.95233637352047\n",
    "\n",
    "transform=T.Compose([T.Resize(256),\n",
    "                     T.RandomCrop(224),\n",
    "                     T.ToTensor(),\n",
    "                     T.Normalize(mean=[global_mean, global_mean, global_mean], \n",
    "                                          std=[global_std, global_std, global_std]),\n",
    "                    ])\n",
    "\n",
    "transformed_dataset = KagglePEDataset(csv_file=train_csv, root_dir=train_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(transformed_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432476\n",
      "358118\n",
      "1790594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "1790589    False\n",
       "1790590    False\n",
       "1790591    False\n",
       "1790592    False\n",
       "1790593     True\n",
       "Name: pe_present_on_image, Length: 1790594, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_sampler))\n",
    "print(len(valid_sampler))\n",
    "print(len(train_sampler) + len(valid_sampler))\n",
    "transformed_dataset.pedataframe.pe_present_on_image == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext101.fc = torch.nn.Linear(resnext101.fc.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1])\n",
      "{'learning_rate': 0.1, 'decay': 0.0005, 'momentum': 0.9, 'epoch': 0, 'train_loss': 0.44564170837402345, 'test_loss': 0.0, 'test_accuracy': 5.584738919040273e-07}\n",
      "Best accuracy: 0.000001\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 1\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "decay = 0.0005\n",
    "schedule = [50, 100]\n",
    "ngpu = 1\n",
    "prefetch = 2\n",
    "log = './'\n",
    "save = './snapshots'\n",
    "\n",
    "# Init logger\n",
    "if not os.path.isdir(log):\n",
    "    os.makedirs(log)\n",
    "log = open(os.path.join(log, 'log.txt'), 'w')\n",
    "state = {'learning_rate':learning_rate,'decay':decay,'momentum':momentum}\n",
    "log.write(json.dumps(state) + '\\n')\n",
    "\n",
    "# Init checkpoints\n",
    "if not os.path.isdir(save):\n",
    "    os.makedirs(save)\n",
    "\n",
    "# Init model, criterion, and optimizer\n",
    "net = resnext101\n",
    "\n",
    "if ngpu > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(ngpu)))\n",
    "\n",
    "if ngpu > 0:\n",
    "    net.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "                            weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=1)\n",
    "\n",
    "train_loader = dataloader\n",
    "test_loader = dataloader\n",
    "\n",
    "# train function (forward, backward, update)\n",
    "def train():\n",
    "    net.train()\n",
    "    loss_avg = 0.0\n",
    "    for batch_idx, sample_batched in enumerate(train_loader):\n",
    "        data = torch.autograd.Variable(sample_batched['image'].cuda())\n",
    "        target = torch.autograd.Variable(sample_batched['pe_present_on_image'].cuda())\n",
    "        \n",
    "        print(data.shape)\n",
    "        print(target.shape)\n",
    "\n",
    "        # forward\n",
    "        output = net(data.float())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.2 + float(loss) * 0.8\n",
    "        \n",
    "        break\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "\n",
    "# test function (forward only)\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    for batch_idx, sample_batched in enumerate(test_loader):\n",
    "        data = torch.autograd.Variable(sample_batched['image'].cuda())\n",
    "        target = torch.autograd.Variable(sample_batched['pe_present_on_image'].cuda())\n",
    "\n",
    "        # forward\n",
    "        output = net(data.float())\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        # accuracy\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += float(pred.eq(target.data).sum())\n",
    "\n",
    "        # test loss average\n",
    "        loss_avg += float(loss)\n",
    "        \n",
    "        break\n",
    "\n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(epochs):\n",
    "    if epoch in schedule:\n",
    "        state['learning_rate'] *= gamma\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['learning_rate']\n",
    "\n",
    "    state['epoch'] = epoch\n",
    "    train()\n",
    "    test()\n",
    "    if state['test_accuracy'] > best_accuracy:\n",
    "        best_accuracy = state['test_accuracy']\n",
    "        torch.save(net.state_dict(), os.path.join(save, 'model.pytorch'))\n",
    "    log.write('%s\\n' % json.dumps(state))\n",
    "    log.flush()\n",
    "    print(state)\n",
    "    print(\"Best accuracy: %f\" % best_accuracy)\n",
    "    break\n",
    "\n",
    "log.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<module 'pydicom.pixel_data_handlers.numpy_handler' from '/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/pydicom/pixel_data_handlers/numpy_handler.py'>, <module 'pydicom.pixel_data_handlers.rle_handler' from '/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/pydicom/pixel_data_handlers/rle_handler.py'>, <module 'pydicom.pixel_data_handlers.gdcm_handler' from '/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/pydicom/pixel_data_handlers/gdcm_handler.py'>, <module 'pydicom.pixel_data_handlers.pillow_handler' from '/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/pydicom/pixel_data_handlers/pillow_handler.py'>, <module 'pydicom.pixel_data_handlers.jpeg_ls_handler' from '/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/pydicom/pixel_data_handlers/jpeg_ls_handler.py'>]\n"
     ]
    }
   ],
   "source": [
    "print(pydicom.config.pixel_data_handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydicom.config.pixel_data_handlers[2] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
