{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.7.7/install/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.7.7/install/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q monai\n",
    "!pip install -q git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1' # specify GPUs locally\n",
    "\n",
    "# libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import albumentations\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor\n",
    "\n",
    "# from apex import amp # I cannot install apex in Kagggle notebook\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "kernel_type = 'monai3d_160_3ch_1e-5_20ep_aug'\n",
    "\n",
    "image_size = 160\n",
    "use_amp = False\n",
    "data_dir = '/net/scc-q32/scratch/rsna-str-pulmonary-embolism-detection-265-jpeg/train'\n",
    "#data_dir = '/net/scc-q32/scratch/rsna-str-pulmonary-embolism-detection-265-jpeg/train'\n",
    "#data_dir = '../input/rsna-str-pe-detection-jpeg-256/train-jpegs'\n",
    "num_workers = 4\n",
    "init_lr = 1e-5\n",
    "out_dim = 9\n",
    "freeze_epo = 0\n",
    "warmup_epo = 1\n",
    "cosine_epo = 2 if DEBUG else 19\n",
    "n_epochs = freeze_epo + warmup_epo + cosine_epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "        'negative_exam_for_pe', # exam level\n",
    "        'rv_lv_ratio_gte_1', # exam level\n",
    "        'rv_lv_ratio_lt_1', # exam level\n",
    "        'leftsided_pe', # exam level\n",
    "        'chronic_pe', # exam level\n",
    "        'rightsided_pe', # exam level\n",
    "        'acute_and_chronic_pe', # exam level\n",
    "        'central_pe', # exam level\n",
    "        'indeterminate' # exam level\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    358142\n",
       "4    358138\n",
       "1    358127\n",
       "0    358125\n",
       "3    358062\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/train.csv')\n",
    "df = pd.read_csv('/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection/train.csv')\n",
    "#df = pd.read_csv('/net/scc-q32/scratch/rsna-str-pulmonary-embolism-detection-265-jpeg/train.csv')\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "np.random.seed(0)\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "print(group_kfold)\n",
    "\n",
    "df['fold'] = -1\n",
    "for i, (_, val_index) in enumerate(group_kfold.split(df, groups=df.StudyInstanceUID)):\n",
    "    df.loc[val_index, 'fold'] = i\n",
    "\n",
    "df.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87348"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study = df.drop_duplicates('StudyInstanceUID')[['StudyInstanceUID','SeriesInstanceUID','fold']+target_cols]\n",
    "df_study.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>fold</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>013358b540bb</td>\n",
       "      <td>2805267980e7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0cee26703028</td>\n",
       "      <td>bac7becd2970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>c28f3d01b14f</td>\n",
       "      <td>7d17c72fd0ce</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>c8fbf1e08ac5</td>\n",
       "      <td>275497911f02</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StudyInstanceUID SeriesInstanceUID  fold  negative_exam_for_pe  \\\n",
       "0       6897fa9de148      2bfbb7fd2e8b     3                     0   \n",
       "124     013358b540bb      2805267980e7     3                     1   \n",
       "269     0cee26703028      bac7becd2970     1                     0   \n",
       "413     c28f3d01b14f      7d17c72fd0ce     1                     0   \n",
       "518     c8fbf1e08ac5      275497911f02     4                     1   \n",
       "\n",
       "     rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                    0                 1             1           0   \n",
       "124                  0                 0             0           0   \n",
       "269                  0                 1             0           1   \n",
       "413                  0                 1             1           0   \n",
       "518                  0                 0             0           0   \n",
       "\n",
       "     rightsided_pe  acute_and_chronic_pe  central_pe  indeterminate  \n",
       "0                1                     0           0              0  \n",
       "124              0                     0           0              0  \n",
       "269              1                     0           0              0  \n",
       "413              0                     0           0              0  \n",
       "518              0                     0           0              0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    df_study = df_study.head(1000)\n",
    "df_study.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from monai.transforms import LoadNifti, Randomizable, apply_transform\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor, RandAffine\n",
    "from monai.utils import get_seed\n",
    "\n",
    "class RSNADataset3D(torch.utils.data.Dataset, Randomizable):\n",
    "    def __init__(self, csv, mode, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "    \n",
    "    def randomize(self) -> None:\n",
    "        MAX_SEED = np.iinfo(np.uint32).max + 1\n",
    "        self._seed = self.R.randint(MAX_SEED, dtype=\"uint32\")    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.randomize()\n",
    "        row = self.csv.iloc[index]\n",
    "        jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.jpg')))\n",
    "        img_lst = [cv2.imread(jpg)[:,:,::-1] for jpg in jpg_lst] \n",
    "        img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            if isinstance(self.transform, Randomizable):\n",
    "                self.transform.set_random_state(seed=self._seed)\n",
    "            img = apply_transform(self.transform, img)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor(row[target_cols]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([ScaleIntensity(), \n",
    "                            Resize((image_size, image_size, image_size)), \n",
    "                            RandAffine( \n",
    "                                      prob=0.5,\n",
    "                                      translate_range=(5, 5, 5),\n",
    "                                      rotate_range=(np.pi * 4, np.pi * 4, np.pi * 4),\n",
    "                                      scale_range=(0.15, 0.15, 0.15),\n",
    "                                      padding_mode='border'),\n",
    "                            ToTensor()])\n",
    "val_transforms = Compose([ScaleIntensity(), Resize((image_size, image_size, image_size)), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c8eb207a89fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_show\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-58ab683f545a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mjpg_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStudyInstanceUID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeriesInstanceUID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimg_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjpg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjpg_lst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_lst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/numpy-1.18.4-py3.7-linux-x86_64.egg/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_show = RSNADataset3D(df_study.head(5), 'train', transform=val_transforms)\n",
    "dataset_show_aug = RSNADataset3D(df_study.head(5), 'train', transform=train_transforms)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,5\n",
    "for i in range(5):\n",
    "    f, axarr = plt.subplots(1,6)\n",
    "    img, label = dataset_show[i]\n",
    "    for j in range(6):        \n",
    "        if j<=2: axarr[j].imshow(img.numpy().transpose(1,2,3,0).mean(axis=j))\n",
    "        elif j==3: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[image_size//2,:,:])\n",
    "        elif j==4: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,image_size//2,:])\n",
    "        elif j==5: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,:,image_size//2])\n",
    "        axarr[j].set_title(f\"Orig {i}\")\n",
    "    f, axarr = plt.subplots(1,6)\n",
    "    img, label = dataset_show_aug[i]    \n",
    "    for j in range(6):        \n",
    "        if j<=2: axarr[j].imshow(img.numpy().transpose(1,2,3,0).mean(axis=j))\n",
    "        elif j==3: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[image_size//2,:,:])\n",
    "        elif j==4: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,image_size//2,:])\n",
    "        elif j==5: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,:,image_size//2])\n",
    "        axarr[j].set_title(f\"Aug {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = nn.BCEWithLogitsLoss()\n",
    "def criterion(logits, target): \n",
    "    loss = bce(logits.view(-1), target.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)       \n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        if not use_amp:\n",
    "            loss.backward()\n",
    "        else:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_epoch(model, loader, is_ext=None, n_test=1, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    LOGITS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "            LOGITS.append(logits.detach().cpu())\n",
    "            TARGETS.append(target.detach().cpu())\n",
    "\n",
    "    val_loss = criterion(torch.cat(LOGITS), torch.cat(TARGETS)).numpy()\n",
    "    PROBS = torch.sigmoid(torch.cat(LOGITS)).numpy().squeeze()    \n",
    "    LOGITS = torch.cat(LOGITS).numpy()\n",
    "    TARGETS = torch.cat(TARGETS).numpy()\n",
    "    \n",
    "    if get_output:\n",
    "        return LOGITS, PROBS, TARGETS\n",
    "    else:\n",
    "        acc = (PROBS.round() == TARGETS).mean() * 100.\n",
    "        auc = roc_auc_score(TARGETS, LOGITS)\n",
    "        return float(val_loss), acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=out_dim).to(device)\n",
    "model\n",
    "fold = 0\n",
    "torch.save(model.state_dict(), f'model1/{kernel_type}_model_fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "    df_train = df_study[(df_study['fold'] != fold)]\n",
    "    df_valid = df_study[(df_study['fold'] == fold)]\n",
    "\n",
    "    dataset_train = RSNADataset3D(df_train, 'train', transform=train_transforms)\n",
    "    dataset_valid = RSNADataset3D(df_valid, 'val', transform=val_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=8, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=8, num_workers=num_workers)\n",
    "\n",
    "    model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=out_dim).to(device)\n",
    "\n",
    "    val_loss_best = 1000\n",
    "    model_file = f'{kernel_type}_best_fold{fold}.pth'\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "    if use_amp:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "#     if len(os.environ['CUDA_VISIBLE_DEVICES'].split(',')) > 1:\n",
    "#         model = nn.DataParallel(model)         \n",
    "        \n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, cosine_epo)\n",
    "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "        scheduler_warmup.step(epoch-1)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer)\n",
    "        val_loss, acc, auc = val_epoch(model, valid_loader)\n",
    "    \n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(val_loss):.5f}, acc: {(acc):.4f}, auc: {(auc):.6f}'\n",
    "        print(content)\n",
    "        with open(f'log_{kernel_type}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')             \n",
    "            \n",
    "        if val_loss < val_loss_best:\n",
    "            print('val_loss_best ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_best, val_loss))\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            val_loss_best = val_loss\n",
    "\n",
    "    torch.save(model.state_dict(), f'model1/{kernel_type}_model_fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [f'model1/monai3d_160_3ch_1e-5_20ep_aug_model_fold{i}.pth' for i in range(1)]\n",
    "#model_files = [f'model1/monai3d_160_3ch_1e-5_20ep_aug_best_fold{i}.pth' for i in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=out_dim).to(device)\n",
    "\n",
    "    try:  # single GPU model_file\n",
    "        model.load_state_dict(torch.load(model_file), strict=True)\n",
    "    except:  # multi GPU model_file\n",
    "        state_dict = torch.load(model_file)\n",
    "        state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    model.eval()    \n",
    "    print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [load_model(model) for model in model_files]\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "            probs = torch.sigmoid(logits)  \n",
    "            print('target: ', target, ' probs: ', probs)\n",
    "\n",
    "def run_test():\n",
    "    data_dir = '/net/scc-q32/scratch/rsna-str-pulmonary-embolism-detection-265-jpeg/'\n",
    "    train_csv = data_dir + 'train.csv'\n",
    "    train_dir = data_dir + 'train/'\n",
    "    \n",
    "    #dataset_train = KagglePEDataset(csv_file=train_csv, root_dir=train_dir)\n",
    "    #train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=1, num_workers=1)\n",
    "    df_train = df_study[(df_study['fold'] != fold)]\n",
    "    dataset_train = RSNADataset3D(df_train, 'train', transform=train_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=8, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
    "\n",
    "    model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=len(target_cols))\n",
    "    #model.load_state_dict(torch.load('monai3d_160_3ch_1e-5_20ep_aug_best_fold0.pth', map_location=device))\n",
    "    model.load_state_dict(torch.load('monai3d_160_3ch_1e-5_20ep_aug_model_fold0.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    test(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-16-58ab683f545a>\", line 25, in __getitem__\n    img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n  File \"<__array_function__ internals>\", line 6, in stack\n  File \"/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/numpy-1.18.4-py3.7-linux-x86_64.egg/numpy/core/shape_base.py\", line 422, in stack\n    raise ValueError('need at least one array to stack')\nValueError: need at least one array to stack\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5e0b864b2c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-fb02228fbdd9>\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-fb02228fbdd9>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/share/pkg.7/pytorch/1.5.1/install/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-16-58ab683f545a>\", line 25, in __getitem__\n    img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n  File \"<__array_function__ internals>\", line 6, in stack\n  File \"/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/numpy-1.18.4-py3.7-linux-x86_64.egg/numpy/core/shape_base.py\", line 422, in stack\n    raise ValueError('need at least one array to stack')\nValueError: need at least one array to stack\n"
     ]
    }
   ],
   "source": [
    "run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
