{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "from tqdm import tqdm as tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2b459164f750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activation will store the features (batched)\n",
    "activation = None\n",
    "\n",
    "# hook to get feature vector in forward pass\n",
    "def hook(model, input, output):\n",
    "    global activation\n",
    "    activation = input\n",
    "\n",
    "number_of_samples = 100000\n",
    "\n",
    "global_mean = 0.0\n",
    "global_std = 500.0\n",
    "transform = T.Normalize(mean=[global_mean], std=[global_std])\n",
    "\n",
    "features_filename = '/scratch/efficientnet-test-features.hdf5'\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# get best model\n",
    "#model = models.resnext50_32x4d(pretrained=True, progress=True)\n",
    "#model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "#model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#model.to(device)\n",
    "\n",
    "#best_model_path = '/projectnb/ece601/kaggle-pulmonary-embolism/cliao25/EC601-Pulmonary-Embolism/SequenceModeling/exp-4-SGD/model-resnext-50-28.pth'\n",
    "#model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "cnn = EfficientNet.from_pretrained('efficientnet-b0',num_classes=1).cuda()\n",
    "cnn._conv_stem.in_channels = 1\n",
    "cnn._conv_stem = torch.nn.Conv2d(1, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "cnn.load_state_dict(\n",
    "    torch.load(\n",
    "        '/projectnb/ece601/kaggle-pulmonary-embolism/jiamingy/efficientnetb0/model-efficientb0-40.pth'\n",
    "    )\n",
    ")\n",
    "#cnn = torch.nn.DataParallel(cnn)\n",
    "model = cnn.to(device)\n",
    "\n",
    "model._fc.register_forward_hook(hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_samples = 26540\n",
    "samples_per_split = 100000\n",
    "train_samples = 70000\n",
    "\n",
    "class KagglePEDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Kaggle PE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, stage, transform=None, split=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.pedataframe = pd.read_csv(csv_file)\n",
    "        self.pos_df = self.pedataframe[self.pedataframe.pe_present_on_image == 1]\n",
    "        self.split_df = self.pedataframe[split*samples_per_split : (split+1)*samples_per_split]\n",
    "        self.neg_df = self.split_df[self.split_df.pe_present_on_image == 0]\n",
    "        self.transform = transform\n",
    "        self.stage = stage\n",
    "        \n",
    "        # data is divided into sets of 100,000 2D slices\n",
    "        # use set 16, 17, and 18 to test\n",
    "        \n",
    "        self.split = split\n",
    "        \n",
    "        self.split_hdf5_filename = '/scratch/npy-' + str(split + 1) + '.hdf5'\n",
    "    \n",
    "    def destroy(self):\n",
    "        ''' For copy on the fly (when scratch space insufficient)'''\n",
    "        os.remove(self.filename )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return number of 2D images. (Each CT slice is an independent image.)\"\"\"\n",
    "        if (self.split + 1) * 100000 > len(self.pedataframe):\n",
    "            return len(self.pedataframe) - (self.split * 100000)\n",
    "        \n",
    "        return 100000\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        subset = self.pedataframe[:len(self)]\n",
    "        pos = subset[subset.pe_present_on_image == 1]\n",
    "        neg = subset[subset.pe_present_on_image == 0]\n",
    "        return 1. / torch.tensor([len(neg), len(pos)], dtype=torch.float)\n",
    "    \n",
    "    def get_targets(self):\n",
    "        subset = self.pedataframe[:len(self)]\n",
    "        return torch.tensor(subset.pe_present_on_image, dtype=torch.long)\n",
    "    \n",
    "    def center_crop(self, crop_size, img):\n",
    "        row = (img.shape[-2] - crop_size) // 2\n",
    "        col = (img.shape[-1] - crop_size) // 2\n",
    "        img = img[row : row + crop_size, col : col + crop_size]\n",
    "        return img\n",
    "    \n",
    "    def random_crop(self, crop_size, img):\n",
    "        row = random.randint(0, img.shape[-2] - crop_size)\n",
    "        col = random.randint(0, img.shape[-1] - crop_size)\n",
    "        img = img[row : row + crop_size, col : col + crop_size]\n",
    "        return img\n",
    "    \n",
    "    def random_flip(self, img):\n",
    "        r = random.randint(0,1)\n",
    "        if r == 0:\n",
    "            img = np.copy(np.flipud(img))\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ''' idx is index into dataframe. '''\n",
    "        \n",
    "        idx = idx + self.split*100000\n",
    "\n",
    "        data_identifier = self.pedataframe.StudyInstanceUID[idx] + \\\n",
    "            '/' + self.pedataframe.SOPInstanceUID[idx]\n",
    "        \n",
    "        # look for image in negative dataset\n",
    "        h5py_file = h5py.File(self.split_hdf5_filename, \"r\")\n",
    "        \n",
    "        img = h5py_file[data_identifier][:]\n",
    "        \n",
    "        #resize 512x512 -> 256x256\n",
    "        img = cv2.resize(img, (256,256), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # center crop 224\n",
    "        if self.stage == 'train':\n",
    "            img = self.random_crop(224, img)\n",
    "            img = self.random_flip(img)\n",
    "        else:\n",
    "            img = self.center_crop(224, img)\n",
    "\n",
    "        # unsqueeze to add channel dimension\n",
    "        img = torch.tensor(img, dtype=torch.float).unsqueeze(0)\n",
    "        h5py_file.close()\n",
    "        \n",
    "        return self.transform(img), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection/'\n",
    "train_csv = data_dir + 'train.csv'\n",
    "train_dir = data_dir + 'train/'\n",
    "train_df = pd.read_csv(train_csv)\n",
    "\n",
    "global_mean = 0.0\n",
    "global_std = 500.0\n",
    "transform = T.Normalize(mean=[global_mean], std=[global_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2832/2832 [02:50<00:00, 16.65it/s]\n",
      "100%|██████████| 3125/3125 [03:05<00:00, 16.84it/s]\n",
      "100%|██████████| 3125/3125 [03:06<00:00, 16.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_set_idx in [17, 16, 15]:\n",
    "    model.eval()\n",
    "\n",
    "    h5py_features_file = h5py.File(features_filename, \"a\")\n",
    "    batch_size = 32\n",
    "    pe_dataset = KagglePEDataset(csv_file=train_csv, stage='valid', transform=transform, split=test_set_idx)\n",
    "    loader = torch.utils.data.DataLoader(pe_dataset, batch_size=batch_size, num_workers=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, idx) in tqdm(loader):\n",
    "            data = data.to(device)\n",
    "            _ = model(data)\n",
    "\n",
    "            # activation[0] is Bx2048. Store this vector\n",
    "            activation = activation[0].detach().cpu()\n",
    "\n",
    "            for sample in range(activation.shape[0]):\n",
    "                sample_idx = idx[sample] # index into dataframe\n",
    "                h5py_features_file.create_dataset(str(sample_idx), data=activation[sample,:])\n",
    "    h5py_features_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2b459176ced0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_filename = '/scratch/resnet-test-features.hdf5'\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# activation will store the features (batched)\n",
    "activation = None\n",
    "\n",
    "# hook to get feature vector in forward pass\n",
    "def hook(model, input, output):\n",
    "    global activation\n",
    "    activation = input\n",
    "\n",
    "# get best model\n",
    "model = models.resnext50_32x4d(pretrained=True, progress=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.to(device)\n",
    "\n",
    "best_model_path = '/projectnb/ece601/kaggle-pulmonary-embolism/cliao25/EC601-Pulmonary-Embolism/SequenceModeling/exp-4-SGD/model-resnext-50-28.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "model.fc.register_forward_hook(hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2832/2832 [05:07<00:00,  9.21it/s]\n",
      "100%|██████████| 3125/3125 [05:37<00:00,  9.25it/s]\n",
      "100%|██████████| 3125/3125 [05:36<00:00,  9.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_set_idx in [17, 16, 15]:\n",
    "    model.eval()\n",
    "\n",
    "    h5py_features_file = h5py.File(features_filename, \"a\")\n",
    "    batch_size = 32\n",
    "    pe_dataset = KagglePEDataset(csv_file=train_csv, stage='valid', transform=transform, split=test_set_idx)\n",
    "    loader = torch.utils.data.DataLoader(pe_dataset, batch_size=batch_size, num_workers=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, idx) in tqdm(loader):\n",
    "            data = data.to(device)\n",
    "            _ = model(data)\n",
    "\n",
    "            # activation[0] is Bx2048. Store this vector\n",
    "            activation = activation[0].detach().cpu()\n",
    "\n",
    "            for sample in range(activation.shape[0]):\n",
    "                sample_idx = idx[sample] # index into dataframe\n",
    "                h5py_features_file.create_dataset(str(sample_idx), data=activation[sample,:])\n",
    "    h5py_features_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
